{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COMP700 Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Author: Alexander Goudemond, Student Number: 219030365"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, the author will summarise the work done so far, as well as display some valuable insights to the reader. The hope is that this assists the reader with understanding how the project progressed, as well as assist the marker by condensing all the knowledge into 1 place, for ease of reference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook has several sections. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project journey"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This project started with the intention to conduct experiments into cell tracking on 10 datasets, provided by the Cell Tracking Challenge (CTC). However, the author ran into so many challenges, that they were not able to explore cell tracking, in the end.\n",
    "\n",
    "Instead, the author focussed on the different techniques one could conduct to prepare the 10 datasets for cell tracking, by investigating both Traditional Segmentation techniques,  and Neural Network Segmentation techniques\n",
    "\n",
    "At the close of the project, the author had enough information to condense and summarise the problems, methods and insights for this goal.\n",
    "\n",
    "This notebook hopes to explain in greater detail what the different experiments conducted yielded, and how the knowledge assisted the project."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Previous Notebook Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This project generated many Jupyter Notebooks, in order to easily work through the 10 datasets. The notebooks saw many revisions, and in the end, 20 presentable notebooks were formulated and used in this project.\n",
    "\n",
    "A table summarising this information is shown here:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|Notebook Number     | Programming Environment | Notebook Size (MB)  | Notebook Summary |\n",
    "|--------------------|-------------------------|---------------------|------------------|\n",
    "|001                 | VS Code                 | 0.004               | *Welcome and Setup* - Explains how to recreate environment to run all notebooks, and dependencies |\n",
    "|002                 | VS Code                 | 5.94                | *Dataset Exploration* - Investigates how to represent images together, colourmaps, and hidden information|\n",
    "|003                 | VS Code                 | 6.67                | *Dataset Colour Exploration* - colourmap comparison and side-by-side video comparison |\n",
    "|004                 | VS Code                 | 19                  | *Dataset Initial Pre-Processing* - preprocessing techniques |\n",
    "|005                 | VS Code                 | 5.59                | *Dataset Secondary Pre-Processing* - preprocessing techniques |\n",
    "|006                 | VS Code                 | 1.13                | *Processing Images* - bulk morphological processing |\n",
    "|007                 | VS Code                 | 16.9                | *Initial Segmentation* - traditional segmentation techniques |\n",
    "|008                 | VS Code                 | 12                  | *Secondary Segmentation* - traditional segmentation technique |\n",
    "|009                 | VS Code                 | 0.0666              | *Bulk Segmentation* - apply bulk thresholding with OpenCV and generate side-by-side video comparison |\n",
    "|010                 | VS Code                 | 1.11                | *Isolate Training Data* - this notebook organises images and masks for segmentation |\n",
    "|011                 | Google Colab            | 5.1                 | *Neural Network Benchmark Preparation* - prepares training data for raw dataset models, as a benchmark |\n",
    "|012                 | Google Colab            | 17.9                | *Neural Network Benchmarks* - trains 18 models on Raw datasets |\n",
    "|013                 | Google Colab            | 27.6                | *Neural Network Benchmark Reflection* - reflect on model success and compare information |\n",
    "|014                 | VS Code                 | 0.0111              | *Dataset Tertiary Pre-Processing* - reviews that processed datasets are best option for Neural Network Segmentation |\n",
    "|015                 | Google Colab            | 0.348               | *Neural Network Processed Preparation* - prepares training data for processed dataset models |\n",
    "|016                 | Google Colab            | 3.3                 | *Neural Network Processed Images* - trains 6 models on processed datasets |\n",
    "|017                 | Google Colab            | 8                   | *Neural Network Processed Reflection* - reflect on model success and compare information |\n",
    "|018                 | Google Colab            | 10.8                | *Neural Network Predictions altogether* - load and predict models side-by-side, as well as mix-and-match models and datasets |\n",
    "|019                 | Google Colab            | 5.9                 | *Neural Network Image Mean IoU Scores* - load models and datasets and conduct image Mean IoU Score |\n",
    "|020                 | VS Code                 |                     | *Conclusion* - condenses all prior work and insights into 1 notebook |\n",
    "|                    | **TOTAL (MB)**              | **139.37**              |                  |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*All 10 Datasets used:*\n",
    "\n",
    "![Visualization of all 10 datasets](003_ColourExploration/Visualization_Of_Cells.jpg \"All 10 Datasets used\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset processing attempts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As one can see, the images below did not assist with the processing of the images..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- \n",
    "\n",
    "![alt text](img_path \"mouse hover text\")\n",
    "\n",
    " -->\n",
    "*Histogram Equalized Images*:\n",
    "\n",
    " ![Histogram Equalized Images](004_InitialPreProcessing/02_HistogramEqualized.png \"Histogram Equalized Images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- \n",
    "\n",
    "![alt text](img_path \"mouse hover text\")\n",
    "\n",
    " -->\n",
    "*127 Thresholded Images*:\n",
    "\n",
    " ![127 Thresholded Images](004_InitialPreProcessing/07_Thresholded_127.png \"127 Thresholded Images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- \n",
    "\n",
    "![alt text](img_path \"mouse hover text\")\n",
    "\n",
    " -->\n",
    "*OpenCV '17' Thresholded Images*:\n",
    "\n",
    "![OpenCV '17' Thresholded Images](007_Initial_Segmentation\\017_Watershed_AdaptedThresholding7_1_pics.jpg \"OpenCV '17' Thresholded Images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- \n",
    "\n",
    "![alt text](img_path \"mouse hover text\")\n",
    "\n",
    " -->\n",
    "*Otsu Thresholding*:\n",
    "\n",
    "![Otsu Thresholding](004_InitialPreProcessing\\0801_OtsuThreshold.png \"Otsu Thresholding\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- \n",
    "\n",
    "![alt text](img_path \"mouse hover text\")\n",
    "\n",
    " -->\n",
    "*Blurred Adaptive Thresholded Mean*:\n",
    "\n",
    " ![Blurred Adaptive Thresholded Mean](004_InitialPreProcessing/0805_BlurAdaptiveThresholdMean.png \"Blurred Adaptive Thresholded Mean\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- \n",
    "\n",
    "![alt text](img_path \"mouse hover text\")\n",
    "\n",
    " -->\n",
    "*Opened At Start Blurred Adaptive Threshold Mean*:\n",
    "\n",
    " ![Opened At Start Blurred Adaptive Threshold Mean](004_InitialPreProcessing/0905_OpenedAtStart_BlurAdaptiveThresholdMean.png \"Opened At Start Blurred Adaptive Threshold Mean\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These images were the best results yet, and were used in the processed image datasets!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- \n",
    "\n",
    "![alt text](img_path \"mouse hover text\")\n",
    "\n",
    " -->\n",
    "*Brightened, Dilated then Opened*:\n",
    "\n",
    " ![Brightened, Dilated then Opened](005_SecondaryPre-Processing/1103_10_Brighten15_Dilated_Opened_Images.png \"Brightened, Dilated then Opened\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "<!-- \n",
    "\n",
    "![alt text](img_path \"mouse hover text\")\n",
    "\n",
    " -->\n",
    "*Brightened, Opened then Eroded*:\n",
    "\n",
    " ![Brightened, Opened then Eroded](005_SecondaryPre-Processing/1103_11_Brighten15_Opened_Eroded_Images.png \"Brightened, Opened then Eroded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset traditional segmentation attempts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately, traditional watershed contained poor results, because the original images were not distinct cells"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "<!-- \n",
    "\n",
    "![alt text](img_path \"mouse hover text\")\n",
    "\n",
    " -->\n",
    "*Default Watershed*:\n",
    "\n",
    " ![Default Watershed](007_Initial_Segmentation/001_Watershed_1_pics.jpg \"Default Watershed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "<!-- \n",
    "\n",
    "![alt text](img_path \"mouse hover text\")\n",
    "\n",
    " -->\n",
    "*Watershed with OpenCV Threshold 17*:\n",
    "\n",
    " ![Watershed with OpenCV Threshold 17](007_Initial_Segmentation/024_WatershedModifiedLast_1_pics.jpg \"Watershed with OpenCV Threshold 17\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other segmentation attempts also failed:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "<!-- \n",
    "\n",
    "![alt text](img_path \"mouse hover text\")\n",
    "\n",
    " -->\n",
    "*Canny Edge Detection*:\n",
    "\n",
    " ![Canny Edge Detection](008_Secondary_Segmentation/001_CannyEdgeDetection_50-150_01.jpg \"Canny Edge Detection\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "<!-- \n",
    "\n",
    "![alt text](img_path \"mouse hover text\")\n",
    "\n",
    " -->\n",
    "*Simple Contours*:\n",
    "\n",
    " ![Simple Contours](008_Secondary_Segmentation/002_SimpleContour_01.jpg \"Simple Contours\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "<!-- \n",
    "\n",
    "![alt text](img_path \"mouse hover text\")\n",
    "\n",
    " -->\n",
    "*Complete Contours*:\n",
    "\n",
    " ![Complete Contours](008_Secondary_Segmentation/003_CompleteContour_02.jpg \"Complete Contours\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "<!-- \n",
    "\n",
    "![alt text](img_path \"mouse hover text\")\n",
    "\n",
    " -->\n",
    "*5 Means Clustering*:\n",
    "\n",
    " ![5 Means Clustering](008_Secondary_Segmentation/004_5MeansClustering_02.jpg \"5 Means Clustering\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "<!-- \n",
    "\n",
    "![alt text](img_path \"mouse hover text\")\n",
    "\n",
    " -->\n",
    "*Region Filled*:\n",
    "\n",
    " ![Region Filled](008_Secondary_Segmentation/006_RegionFilled_01.jpg \"Region Filled\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Useful Videos showing Colourmaps and their affect on the datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following contain information that assisted the author with visualising the information present over time. More examples are available in the relevant folder!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video src=\"003_ColourExploration//BF-C2DL-HSC_01.mp4\" controls  >\n",
       "      Your browser does not support the <code>video</code> element.\n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Video(\"003_ColourExploration//BF-C2DL-HSC_01.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video src=\"003_ColourExploration//DIC-C2DH-HeLa_01.mp4\" controls  >\n",
       "      Your browser does not support the <code>video</code> element.\n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Video(\"003_ColourExploration//DIC-C2DH-HeLa_01.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video src=\"003_ColourExploration//Fluo-C2DL-Huh7_01.mp4\" controls  >\n",
       "      Your browser does not support the <code>video</code> element.\n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Video(\"003_ColourExploration//Fluo-C2DL-Huh7_01.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video src=\"003_ColourExploration//Fluo-C2DL-MSC_01.mp4\" controls  >\n",
       "      Your browser does not support the <code>video</code> element.\n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Video(\"003_ColourExploration//Fluo-C2DL-MSC_01.mp4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Useful Videos showing traditional segmentation techniques alongisde segmentation masks and tracking masks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following contain information that assisted the author with visualising the information present over time. More examples are available in the relevant folder!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video src=\"009_Segmentation_Videos//BF-C2DL-HSC.mp4\" controls  >\n",
       "      Your browser does not support the <code>video</code> element.\n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Video(\"009_Segmentation_Videos//BF-C2DL-HSC.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video src=\"009_Segmentation_Videos//Fluo-N2DH-GOWT1.mp4\" controls  >\n",
       "      Your browser does not support the <code>video</code> element.\n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Video(\"009_Segmentation_Videos//Fluo-N2DH-GOWT1.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video src=\"009_Segmentation_Videos//PhC-C2DH-U373.mp4\" controls  >\n",
       "      Your browser does not support the <code>video</code> element.\n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "Video(\"009_Segmentation_Videos//PhC-C2DH-U373.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video src=\"009_Segmentation_Videos//PhC-C2DL-PSC.mp4\" controls  >\n",
       "      Your browser does not support the <code>video</code> element.\n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Video(\"009_Segmentation_Videos//PhC-C2DL-PSC.mp4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Data and Their Videos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following contain information that assisted the author with visualising the information present over time. More examples are available in the relevant folder!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video src=\"010_Training_Data_Videos//GT//BF-C2DL-HSC_02.mp4\" controls  >\n",
       "      Your browser does not support the <code>video</code> element.\n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Video(\"010_Training_Data_Videos//GT//BF-C2DL-HSC_02.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video src=\"010_Training_Data_Videos//GT//Fluo-N2DH-GOWT1_01.mp4\" controls  >\n",
       "      Your browser does not support the <code>video</code> element.\n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Video(\"010_Training_Data_Videos//GT//Fluo-N2DH-GOWT1_01.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video src=\"010_Training_Data_Videos//ST//DIC-C2DH-HeLa_02.mp4\" controls  >\n",
       "      Your browser does not support the <code>video</code> element.\n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "Video(\"010_Training_Data_Videos//ST//DIC-C2DH-HeLa_02.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video src=\"010_Training_Data_Videos//ST//PhC-C2DL-PSC_02.mp4\" controls  >\n",
       "      Your browser does not support the <code>video</code> element.\n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "Video(\"010_Training_Data_Videos//ST//PhC-C2DL-PSC_02.mp4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UNet Implementation and Methodology"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is a collection of useful information to explain why this project completed tasks in the way it did. What is included in this cell is a description to explain it in detail\n",
    "\n",
    "The goal of this project was to compare segmentation techniques of 10 datasets from the CTC website. When the author moved onto Neural Network Segmentation, they encountered many hurdles to overcome:\n",
    "\n",
    "- Convolutional Neural Networks (CNNs) seem to require images to be in float pixel range, NOT integer pixel range. Forcing the images to be in integer range results in the model you are training receiving a loss function with NaN values (*not a number* in python)\n",
    "\n",
    "- The masks that were provided were multiclass masks - meaning that every indidivual cell was assigned a unique colour. This resulted in the model attempting to classify anywhere from 2 to 256 possible classes - which hurt the training significantly. The masks needed to be converted into binary masks before being used\n",
    "\n",
    "- Early processing of the images saved the masks under a JPG extension - leading to the compression method from blurring the boundaries between mask values. this resulted in a mask with 12 classes being transformed into a class with upwards of 150... The author had to return and ensure the training images were saved as PNG, if conversion was necessary at all\n",
    "\n",
    "- It is not possible to simply feed the entire collection of images into the UNet model, as each model has 1 of 12 possible dimensions! (Refer to the table below) This means that the author needed to decide on whether to resize the images, or crop them...\n",
    "\n",
    "    - It was discovered that resizing the images affected the accuracy of the training model, and lost valuable data. For square images, it also introduced distortion\n",
    "\n",
    "    - It was discovered that cropping the images would involve the largest image (1036, 1070, 3) would need to be reduced to the smallest image (512, 512, 3) - leading to under half of the original image being lost!\n",
    "\n",
    "    - To address these challenges, cutting each image into smaller pieces of a consistent size if a good compromise. This is exactly what Patchify does - it produces square 'cake slices' or 'patches' or 'jigsaw pieces' out of a larger image. These patches then have a consistent size, and may be fed into the model!\n",
    "\n",
    "- Once the patches of the image have been generated, the model also needs corresponding patches of masks! So the author needed to ensure the masks were patchified alongside the images, before training\n",
    "\n",
    "- Ensuring the image paths were sorted before reading and patchifying the images was essential, as Google seems to randomly save images, for some reason (perhaps under a Hash Map?) The author struggled to identify this issue as in windows the filenames are sorted by default!\n",
    "\n",
    "- Once the model has been trained, the model can then predict and compare the patchified predictions against the patchified masks. However, this is just 1 way of calculating the Mean IoU score! Another technique is to calculate the score on the entire image, which is what was achieved in notebook 019\n",
    "\n",
    "- This technique is computationaly involved, and the user needs to be careful when using usage restrictions in Google Colab, but allows any image of any dimension to be predicted in a Unet model!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that we have the following information on dataset dimenions:\n",
    "\n",
    "Dataset Name        | Folder Dimensions |\n",
    "|-------------------|-------------------|\n",
    "BF-C2DL-HSC         | (1010,1010,3)     |\n",
    "BF-C2DL-MuSC        | (1036,1070,3)     |\n",
    "DIC-C2DH-HeLa       | (512,512,3)       |\n",
    "Fluo-C2DL-Huh7      | (1024,1024,3)     |\n",
    "Fluo-C2DL-MSC/01    | 832,992,3)        |\n",
    "Fluo-C2DL-MSC/02    | 782,1200,3)       |\n",
    "Fluo-N2DH-SIM+/01   | (690,628,3)       |\n",
    "Fluo-N2DH-SIM+/02   | (773,739,3)       |\n",
    "Fluo-N2DH-GOWT1     | (1024,1024,3)     |\n",
    "Fluo-N2DL-HeLa      | (700,1100,3)      |\n",
    "PhC-C2DH-U373       | (520,696,3)       |\n",
    "PhC-C2DL-PSC        | (576,720,3)       |\n",
    "\n",
    "As well as quantity of images:\n",
    "\n",
    "| Dataset Name      | GT Mask Quantity | ST Mask Quantity |\n",
    "|-------------------|------------------|------------------|\n",
    "| BF-C2DL-HSC/01    | 49               | 1764             |\n",
    "| BF-C2DL-HSC/02    | 8                | 1764             |\n",
    "| BF-C2DL-MuSC/01   | 50               | 1376             |\n",
    "| BF-C2DL-MuSC/02   | 50               | 1376             |\n",
    "| DIC-C2DH-HeLa/01  | 9                | 84               |\n",
    "| DIC-C2DH-HeLa/02  | 9                | 84               |\n",
    "| Fluo-C2DL-Huh7/01 | 8                | N/A              |\n",
    "| Fluo-C2DL-Huh7/02 | 5                | N/A              |\n",
    "| Fluo-C2DL-MSC/01  | 18               | 48               |\n",
    "| Fluo-C2DL-MSC/02  | 33               | 48               |\n",
    "| Fluo-N2DH-SIM+/01 | 30               | N/A              |\n",
    "| Fluo-N2DH-SIM+/02 | 20               | N/A              |\n",
    "| Fluo-N2DH-GOWT1/01| 65               | 92               |\n",
    "| Fluo-N2DH-GOWT1/02| 150              | 92               |\n",
    "| Fluo-N2DL-HeLa/01 | 28               | 92               |\n",
    "| Fluo-N2DL-HeLa/02 | 8                | 92               |\n",
    "| PhC-C2DH-U373/01  | 15               | 115              |\n",
    "| PhC-C2DH-U373/02  | 19               | 115              |\n",
    "| PhC-C2DL-PSC/01   | 2                | 300              |\n",
    "| PhC-C2DL-PSC/02   | 2                | 300              |\n",
    "| **Total**         | **578**          | **7742**         |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- \n",
    "\n",
    "![alt text](img_path \"mouse hover text\")\n",
    "\n",
    " -->\n",
    "*Project Methodology*:\n",
    "\n",
    " ![Project Methodology](Project_Methodology(1).png \"Project Methodology\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load model that was generated in Google Drive and Colab:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: google-api-python-client in c:\\users\\g5\\anaconda3\\envs\\python_gpu\\lib\\site-packages (2.65.0)\n",
      "Requirement already satisfied: google-auth<3.0.0dev,>=1.19.0 in c:\\users\\g5\\anaconda3\\envs\\python_gpu\\lib\\site-packages (from google-api-python-client) (2.14.1)\n",
      "Requirement already satisfied: uritemplate<5,>=3.0.1 in c:\\users\\g5\\anaconda3\\envs\\python_gpu\\lib\\site-packages (from google-api-python-client) (4.1.1)\n",
      "Requirement already satisfied: google-auth-httplib2>=0.1.0 in c:\\users\\g5\\anaconda3\\envs\\python_gpu\\lib\\site-packages (from google-api-python-client) (0.1.0)\n",
      "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5 in c:\\users\\g5\\anaconda3\\envs\\python_gpu\\lib\\site-packages (from google-api-python-client) (2.10.2)\n",
      "Requirement already satisfied: httplib2<1dev,>=0.15.0 in c:\\users\\g5\\anaconda3\\envs\\python_gpu\\lib\\site-packages (from google-api-python-client) (0.21.0)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.56.2 in c:\\users\\g5\\anaconda3\\envs\\python_gpu\\lib\\site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-api-python-client) (1.56.4)\n",
      "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5 in c:\\users\\g5\\anaconda3\\envs\\python_gpu\\lib\\site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-api-python-client) (3.20.3)\n",
      "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in c:\\users\\g5\\anaconda3\\envs\\python_gpu\\lib\\site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-api-python-client) (2.28.1)\n",
      "Requirement already satisfied: six>=1.9.0 in c:\\users\\g5\\anaconda3\\envs\\python_gpu\\lib\\site-packages (from google-auth<3.0.0dev,>=1.19.0->google-api-python-client) (1.16.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\g5\\anaconda3\\envs\\python_gpu\\lib\\site-packages (from google-auth<3.0.0dev,>=1.19.0->google-api-python-client) (4.9)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\g5\\anaconda3\\envs\\python_gpu\\lib\\site-packages (from google-auth<3.0.0dev,>=1.19.0->google-api-python-client) (5.2.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\g5\\anaconda3\\envs\\python_gpu\\lib\\site-packages (from google-auth<3.0.0dev,>=1.19.0->google-api-python-client) (0.2.8)\n",
      "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in c:\\users\\g5\\anaconda3\\envs\\python_gpu\\lib\\site-packages (from httplib2<1dev,>=0.15.0->google-api-python-client) (3.0.9)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\g5\\anaconda3\\envs\\python_gpu\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0dev,>=1.19.0->google-api-python-client) (0.4.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\g5\\anaconda3\\envs\\python_gpu\\lib\\site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-api-python-client) (3.4)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\g5\\anaconda3\\envs\\python_gpu\\lib\\site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-api-python-client) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\g5\\anaconda3\\envs\\python_gpu\\lib\\site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-api-python-client) (1.26.12)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\g5\\anaconda3\\envs\\python_gpu\\lib\\site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-api-python-client) (2022.9.24)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\g5\\anaconda3\\envs\\python_gpu\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\g5\\anaconda3\\envs\\python_gpu\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\g5\\anaconda3\\envs\\python_gpu\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\g5\\anaconda3\\envs\\python_gpu\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\g5\\anaconda3\\envs\\python_gpu\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\g5\\anaconda3\\envs\\python_gpu\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade google-api-python-client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: protobuf==3.20.* in c:\\users\\g5\\anaconda3\\envs\\python_gpu\\lib\\site-packages (3.20.3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\g5\\anaconda3\\envs\\python_gpu\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\g5\\anaconda3\\envs\\python_gpu\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\g5\\anaconda3\\envs\\python_gpu\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\g5\\anaconda3\\envs\\python_gpu\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\g5\\anaconda3\\envs\\python_gpu\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\g5\\anaconda3\\envs\\python_gpu\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "!pip install protobuf==3.20.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"UNET_Model_Dimension_256_2\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " Input (InputLayer)             [(None, 256, 256, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " c1_a (Conv2D)                  (None, 256, 256, 16  448         ['Input[0][0]']                  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " c1_b (Dropout)                 (None, 256, 256, 16  0           ['c1_a[0][0]']                   \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " c1_c (Conv2D)                  (None, 256, 256, 16  2320        ['c1_b[0][0]']                   \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " p1 (MaxPooling2D)              (None, 128, 128, 16  0           ['c1_c[0][0]']                   \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " c2_a (Conv2D)                  (None, 128, 128, 32  4640        ['p1[0][0]']                     \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " c2_b (Dropout)                 (None, 128, 128, 32  0           ['c2_a[0][0]']                   \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " c2_c (Conv2D)                  (None, 128, 128, 32  9248        ['c2_b[0][0]']                   \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " p2 (MaxPooling2D)              (None, 64, 64, 32)   0           ['c2_c[0][0]']                   \n",
      "                                                                                                  \n",
      " c3_a (Conv2D)                  (None, 64, 64, 64)   18496       ['p2[0][0]']                     \n",
      "                                                                                                  \n",
      " c3_b (Dropout)                 (None, 64, 64, 64)   0           ['c3_a[0][0]']                   \n",
      "                                                                                                  \n",
      " c3_c (Conv2D)                  (None, 64, 64, 64)   36928       ['c3_b[0][0]']                   \n",
      "                                                                                                  \n",
      " p3 (MaxPooling2D)              (None, 32, 32, 64)   0           ['c3_c[0][0]']                   \n",
      "                                                                                                  \n",
      " c4_a (Conv2D)                  (None, 32, 32, 128)  73856       ['p3[0][0]']                     \n",
      "                                                                                                  \n",
      " c4_b (Dropout)                 (None, 32, 32, 128)  0           ['c4_a[0][0]']                   \n",
      "                                                                                                  \n",
      " c4_c (Conv2D)                  (None, 32, 32, 128)  147584      ['c4_b[0][0]']                   \n",
      "                                                                                                  \n",
      " p4 (MaxPooling2D)              (None, 16, 16, 128)  0           ['c4_c[0][0]']                   \n",
      "                                                                                                  \n",
      " c5_a (Conv2D)                  (None, 16, 16, 256)  295168      ['p4[0][0]']                     \n",
      "                                                                                                  \n",
      " c5_b (Dropout)                 (None, 16, 16, 256)  0           ['c5_a[0][0]']                   \n",
      "                                                                                                  \n",
      " c5_c (Conv2D)                  (None, 16, 16, 256)  590080      ['c5_b[0][0]']                   \n",
      "                                                                                                  \n",
      " u6_a (Conv2DTranspose)         (None, 32, 32, 128)  131200      ['c5_c[0][0]']                   \n",
      "                                                                                                  \n",
      " u6_b (Concatenate)             (None, 32, 32, 256)  0           ['u6_a[0][0]',                   \n",
      "                                                                  'c4_c[0][0]']                   \n",
      "                                                                                                  \n",
      " c6_a (Conv2D)                  (None, 32, 32, 128)  295040      ['u6_b[0][0]']                   \n",
      "                                                                                                  \n",
      " c6_b (Dropout)                 (None, 32, 32, 128)  0           ['c6_a[0][0]']                   \n",
      "                                                                                                  \n",
      " c6_c (Conv2D)                  (None, 32, 32, 128)  147584      ['c6_b[0][0]']                   \n",
      "                                                                                                  \n",
      " u7_a (Conv2DTranspose)         (None, 64, 64, 64)   32832       ['c6_c[0][0]']                   \n",
      "                                                                                                  \n",
      " u7_b (Concatenate)             (None, 64, 64, 128)  0           ['u7_a[0][0]',                   \n",
      "                                                                  'c3_c[0][0]']                   \n",
      "                                                                                                  \n",
      " c7_a (Conv2D)                  (None, 64, 64, 64)   73792       ['u7_b[0][0]']                   \n",
      "                                                                                                  \n",
      " c7_b (Dropout)                 (None, 64, 64, 64)   0           ['c7_a[0][0]']                   \n",
      "                                                                                                  \n",
      " c7_c (Conv2D)                  (None, 64, 64, 64)   36928       ['c7_b[0][0]']                   \n",
      "                                                                                                  \n",
      " u8_a (Conv2DTranspose)         (None, 128, 128, 32  8224        ['c7_c[0][0]']                   \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " u8_b (Concatenate)             (None, 128, 128, 64  0           ['u8_a[0][0]',                   \n",
      "                                )                                 'c2_c[0][0]']                   \n",
      "                                                                                                  \n",
      " c8_a (Conv2D)                  (None, 128, 128, 32  18464       ['u8_b[0][0]']                   \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " c8_b (Dropout)                 (None, 128, 128, 32  0           ['c8_a[0][0]']                   \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " c8_c (Conv2D)                  (None, 128, 128, 32  9248        ['c8_b[0][0]']                   \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " u9_a (Conv2DTranspose)         (None, 256, 256, 16  2064        ['c8_c[0][0]']                   \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " u9_b (Concatenate)             (None, 256, 256, 32  0           ['u9_a[0][0]',                   \n",
      "                                )                                 'c1_c[0][0]']                   \n",
      "                                                                                                  \n",
      " c9_a (Conv2D)                  (None, 256, 256, 16  4624        ['u9_b[0][0]']                   \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " c9_b (Dropout)                 (None, 256, 256, 16  0           ['c9_a[0][0]']                   \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " c9_c (Conv2D)                  (None, 256, 256, 16  2320        ['c9_b[0][0]']                   \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " Output (Conv2D)                (None, 256, 256, 3)  51          ['c9_c[0][0]']                   \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,941,139\n",
      "Trainable params: 1,941,139\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Code representation of architecture:\n",
    "from keras.models import load_model\n",
    "import google\n",
    "\n",
    "def getModel(path, model_name):\n",
    "    return load_model(path + model_name)\n",
    "###\n",
    "# Google Drive and Google Colab Content\\COMP700_UNet_Models\\GT_256\\gt_256_model_2\n",
    "model = getModel(\"Google Drive and Google Colab Content//COMP700_UNet_Models//GT_256//\", \"gt_256_model_2\")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Full output here:\n",
    "\n",
    "```\n",
    "Model: \"UNET_Model_Dimension_256_2\"\n",
    "__________________________________________________________________________________________________\n",
    " Layer (type)                   Output Shape         Param #     Connected to                     \n",
    "==================================================================================================\n",
    " Input (InputLayer)             [(None, 256, 256, 3  0           []                               \n",
    "                                )]                                                                \n",
    "                                                                                                  \n",
    " c1_a (Conv2D)                  (None, 256, 256, 16  448         ['Input[0][0]']                  \n",
    "                                )                                                                 \n",
    "                                                                                                  \n",
    " c1_b (Dropout)                 (None, 256, 256, 16  0           ['c1_a[0][0]']                   \n",
    "                                )                                                                 \n",
    "                                                                                                  \n",
    " c1_c (Conv2D)                  (None, 256, 256, 16  2320        ['c1_b[0][0]']                   \n",
    "                                )                                                                 \n",
    "                                                                                                  \n",
    " p1 (MaxPooling2D)              (None, 128, 128, 16  0           ['c1_c[0][0]']                   \n",
    "                                )                                                                 \n",
    "                                                                                                  \n",
    " c2_a (Conv2D)                  (None, 128, 128, 32  4640        ['p1[0][0]']                     \n",
    "                                )                                                                 \n",
    "                                                                                                  \n",
    " c2_b (Dropout)                 (None, 128, 128, 32  0           ['c2_a[0][0]']                   \n",
    "                                )                                                                 \n",
    "                                                                                                  \n",
    " c2_c (Conv2D)                  (None, 128, 128, 32  9248        ['c2_b[0][0]']                   \n",
    "                                )                                                                 \n",
    "                                                                                                  \n",
    " p2 (MaxPooling2D)              (None, 64, 64, 32)   0           ['c2_c[0][0]']                   \n",
    "                                                                                                  \n",
    " c3_a (Conv2D)                  (None, 64, 64, 64)   18496       ['p2[0][0]']                     \n",
    "                                                                                                  \n",
    " c3_b (Dropout)                 (None, 64, 64, 64)   0           ['c3_a[0][0]']                   \n",
    "                                                                                                  \n",
    " c3_c (Conv2D)                  (None, 64, 64, 64)   36928       ['c3_b[0][0]']                   \n",
    "                                                                                                  \n",
    " p3 (MaxPooling2D)              (None, 32, 32, 64)   0           ['c3_c[0][0]']                   \n",
    "                                                                                                  \n",
    " c4_a (Conv2D)                  (None, 32, 32, 128)  73856       ['p3[0][0]']                     \n",
    "                                                                                                  \n",
    " c4_b (Dropout)                 (None, 32, 32, 128)  0           ['c4_a[0][0]']                   \n",
    "                                                                                                  \n",
    " c4_c (Conv2D)                  (None, 32, 32, 128)  147584      ['c4_b[0][0]']                   \n",
    "                                                                                                  \n",
    " p4 (MaxPooling2D)              (None, 16, 16, 128)  0           ['c4_c[0][0]']                   \n",
    "                                                                                                  \n",
    " c5_a (Conv2D)                  (None, 16, 16, 256)  295168      ['p4[0][0]']                     \n",
    "                                                                                                  \n",
    " c5_b (Dropout)                 (None, 16, 16, 256)  0           ['c5_a[0][0]']                   \n",
    "                                                                                                  \n",
    " c5_c (Conv2D)                  (None, 16, 16, 256)  590080      ['c5_b[0][0]']                   \n",
    "                                                                                                  \n",
    " u6_a (Conv2DTranspose)         (None, 32, 32, 128)  131200      ['c5_c[0][0]']                   \n",
    "                                                                                                  \n",
    " u6_b (Concatenate)             (None, 32, 32, 256)  0           ['u6_a[0][0]',                   \n",
    "                                                                  'c4_c[0][0]']                   \n",
    "                                                                                                  \n",
    " c6_a (Conv2D)                  (None, 32, 32, 128)  295040      ['u6_b[0][0]']                   \n",
    "                                                                                                  \n",
    " c6_b (Dropout)                 (None, 32, 32, 128)  0           ['c6_a[0][0]']                   \n",
    "                                                                                                  \n",
    " c6_c (Conv2D)                  (None, 32, 32, 128)  147584      ['c6_b[0][0]']                   \n",
    "                                                                                                  \n",
    " u7_a (Conv2DTranspose)         (None, 64, 64, 64)   32832       ['c6_c[0][0]']                   \n",
    "                                                                                                  \n",
    " u7_b (Concatenate)             (None, 64, 64, 128)  0           ['u7_a[0][0]',                   \n",
    "                                                                  'c3_c[0][0]']                   \n",
    "                                                                                                  \n",
    " c7_a (Conv2D)                  (None, 64, 64, 64)   73792       ['u7_b[0][0]']                   \n",
    "                                                                                                  \n",
    " c7_b (Dropout)                 (None, 64, 64, 64)   0           ['c7_a[0][0]']                   \n",
    "                                                                                                  \n",
    " c7_c (Conv2D)                  (None, 64, 64, 64)   36928       ['c7_b[0][0]']                   \n",
    "                                                                                                  \n",
    " u8_a (Conv2DTranspose)         (None, 128, 128, 32  8224        ['c7_c[0][0]']                   \n",
    "                                )                                                                 \n",
    "                                                                                                  \n",
    " u8_b (Concatenate)             (None, 128, 128, 64  0           ['u8_a[0][0]',                   \n",
    "                                )                                 'c2_c[0][0]']                   \n",
    "                                                                                                  \n",
    " c8_a (Conv2D)                  (None, 128, 128, 32  18464       ['u8_b[0][0]']                   \n",
    "                                )                                                                 \n",
    "                                                                                                  \n",
    " c8_b (Dropout)                 (None, 128, 128, 32  0           ['c8_a[0][0]']                   \n",
    "                                )                                                                 \n",
    "                                                                                                  \n",
    " c8_c (Conv2D)                  (None, 128, 128, 32  9248        ['c8_b[0][0]']                   \n",
    "                                )                                                                 \n",
    "                                                                                                  \n",
    " u9_a (Conv2DTranspose)         (None, 256, 256, 16  2064        ['c8_c[0][0]']                   \n",
    "                                )                                                                 \n",
    "                                                                                                  \n",
    " u9_b (Concatenate)             (None, 256, 256, 32  0           ['u9_a[0][0]',                   \n",
    "                                )                                 'c1_c[0][0]']                   \n",
    "                                                                                                  \n",
    " c9_a (Conv2D)                  (None, 256, 256, 16  4624        ['u9_b[0][0]']                   \n",
    "                                )                                                                 \n",
    "                                                                                                  \n",
    " c9_b (Dropout)                 (None, 256, 256, 16  0           ['c9_a[0][0]']                   \n",
    "                                )                                                                 \n",
    "                                                                                                  \n",
    " c9_c (Conv2D)                  (None, 256, 256, 16  2320        ['c9_b[0][0]']                   \n",
    "                                )                                                                 \n",
    "                                                                                                  \n",
    " Output (Conv2D)                (None, 256, 256, 3)  51          ['c9_c[0][0]']                   \n",
    "                                                                                                  \n",
    "==================================================================================================\n",
    "Total params: 1,941,139\n",
    "Trainable params: 1,941,139\n",
    "Non-trainable params: 0\n",
    "__________________________________________________________________________________________________\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- \n",
    "\n",
    "![alt text](img_path \"mouse hover text\")\n",
    "\n",
    " -->\n",
    "*Unet Architecture*:\n",
    "\n",
    " ![Unet Architecture](Unet_Model_V4.png \"Unet Architecture\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('python_gpu')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b82f63144f2c45b2313238722d81a7c4b83bac7fe75f18d324f42bf6a6cba197"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
