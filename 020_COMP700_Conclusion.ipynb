{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COMP700 Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Author: Alexander Goudemond, Student Number: 219030365"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, the author will summarise the work done so far, as well as display some valuable insights to the reader. The hope is that this assists the reader with understanding how the project progressed, as well as assist the marker by condensing all the knowledge into 1 place, for ease of reference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook has several sections. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project journey"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This project started with the intention to conduct experiments into cell tracking on 10 datasets, provided by the Cell Tracking Challenge (CTC). However, the author ran into so many challenges, that they were not able to explore cell tracking, in the end.\n",
    "\n",
    "Instead, the author focussed on the different techniques one could conduct to prepare the 10 datasets for cell tracking, by investigating both Traditional Segmentation techniques,  and Neural Network Segmentation techniques\n",
    "\n",
    "At the close of the project, the author had enough information to condense and summarise the problems, methods and insights for this goal.\n",
    "\n",
    "This notebook hopes to explain in greater detail what the different experiments conducted yielded, and how the knowledge assisted the project."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Previous Notebook Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This project generated many Jupyter Notebooks, in order to easily work through the 10 datasets. The notebooks saw many revisions, and in the end, 20 presentable notebooks were formulated and used in this project.\n",
    "\n",
    "A table summarising this information is shown here:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|Notebook Number     | Programming Environment | Notebook Size (MB)  | Notebook Summary |\n",
    "|--------------------|-------------------------|---------------------|------------------|\n",
    "|001                 | VS Code                 | 0.004               | *Welcome and Setup* - Explains how to recreate environment to run all notebooks, and dependencies |\n",
    "|002                 | VS Code                 | 5.94                | *Dataset Exploration* - Investigates how to represent images together, colourmaps, and hidden information|\n",
    "|003                 | VS Code                 | 6.67                | *Dataset Colour Exploration* - colourmap comparison and side-by-side video comparison |\n",
    "|004                 | VS Code                 | 19                  | *Dataset Initial Pre-Processing* - preprocessing techniques |\n",
    "|005                 | VS Code                 | 5.59                | *Dataset Secondary Pre-Processing* - preprocessing techniques |\n",
    "|006                 | VS Code                 | 1.13                | *Processing Images* - bulk morphological processing |\n",
    "|007                 | VS Code                 | 16.9                | *Initial Segmentation* - traditional segmentation techniques |\n",
    "|008                 | VS Code                 | 12                  | *Secondary Segmentation* - traditional segmentation technique |\n",
    "|009                 | VS Code                 | 0.0666              | *Bulk Segmentation* - apply bulk thresholding with OpenCV and generate side-by-side video comparison |\n",
    "|010                 | VS Code                 | 1.11                | *Isolate Training Data* - this notebook organises images and masks for segmentation |\n",
    "|011                 | Google Colab            | 5.1                 | *Neural Network Benchmark Preparation* - prepares training data for raw dataset models, as a benchmark |\n",
    "|012                 | Google Colab            | 17.9                | *Neural Network Benchmarks* - trains 18 models on Raw datasets |\n",
    "|013                 | Google Colab            | 27.6                | *Neural Network Benchmark Reflection* - reflect on model success and compare information |\n",
    "|014                 | VS Code                 | 0.0111              | *Dataset Tertiary Pre-Processing* - reviews that processed datasets are best option for Neural Network Segmentation |\n",
    "|015                 | Google Colab            | 0.348               | *Neural Network Processed Preparation* - prepares training data for processed dataset models |\n",
    "|016                 | Google Colab            | 3.3                 | *Neural Network Processed Images* - trains 6 models on processed datasets |\n",
    "|017                 | Google Colab            | 8                   | *Neural Network Processed Reflection* - reflect on model success and compare information |\n",
    "|018                 | Google Colab            | 10.8                | *Neural Network Predictions altogether* - load and predict models side-by-side, as well as mix-and-match models and datasets |\n",
    "|019                 | Google Colab            | 5.9                 | *Neural Network Image Mean IoU Scores* - load models and datasets and conduct image Mean IoU Score |\n",
    "|020                 | VS Code                 |                     | *Conclusion* - condenses all prior work and insights into 1 notebook |\n",
    "|                    | **TOTAL (MB)**              | **139.37**              |                  |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*All 10 Datasets used:*\n",
    "\n",
    "![Visualization of all 10 datasets](003_ColourExploration/Visualization_Of_Cells.jpg \"All 10 Datasets used\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset processing attempts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- \n",
    "\n",
    "![alt text](img_path \"mouse hover text\")\n",
    "\n",
    " -->\n",
    "*Histogram Equalized Images*:\n",
    "\n",
    " ![Histogram Equalized Images](004_InitialPreProcessing/02_HistogramEqualized.png \"Histogram Equalized Images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- \n",
    "\n",
    "![alt text](img_path \"mouse hover text\")\n",
    "\n",
    " -->\n",
    "*127 Thresholded Images*:\n",
    "\n",
    " ![127 Thresholded Images](004_InitialPreProcessing/07_Thresholded_127.png \"127 Thresholded Images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- \n",
    "\n",
    "![alt text](img_path \"mouse hover text\")\n",
    "\n",
    " -->\n",
    "*OpenCV '17' Thresholded Images*:\n",
    "\n",
    "![OpenCV '17' Thresholded Images](007_Initial_Segmentation\\017_Watershed_AdaptedThresholding7_1_pics.jpg \"OpenCV '17' Thresholded Images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- \n",
    "\n",
    "![alt text](img_path \"mouse hover text\")\n",
    "\n",
    " -->\n",
    "*Otsu Thresholding*:\n",
    "\n",
    "![Otsu Thresholding](004_InitialPreProcessing\\0801_OtsuThreshold.png \"Otsu Thresholding\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- \n",
    "\n",
    "![alt text](img_path \"mouse hover text\")\n",
    "\n",
    " -->\n",
    "*Blurred Adaptive Thresholded Mean*:\n",
    "\n",
    " ![Blurred Adaptive Thresholded Mean](004_InitialPreProcessing/0805_BlurAdaptiveThresholdMean.png \"Blurred Adaptive Thresholded Mean\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- \n",
    "\n",
    "![alt text](img_path \"mouse hover text\")\n",
    "\n",
    " -->\n",
    "*Opened At Start Blurred Adaptive Threshold Mean*:\n",
    "\n",
    " ![Opened At Start Blurred Adaptive Threshold Mean](004_InitialPreProcessing/0905_OpenedAtStart_BlurAdaptiveThresholdMean.png \"Opened At Start Blurred Adaptive Threshold Mean\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- \n",
    "\n",
    "![alt text](img_path \"mouse hover text\")\n",
    "\n",
    " -->\n",
    "*Brightened, Dilated then Opened*:\n",
    "\n",
    " ![Brightened, Dilated then Opened](005_SecondaryPre-Processing/1103_10_Brighten15_Dilated_Opened_Images.png \"Brightened, Dilated then Opened\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "<!-- \n",
    "\n",
    "![alt text](img_path \"mouse hover text\")\n",
    "\n",
    " -->\n",
    "*Brightened, Opened then Eroded*:\n",
    "\n",
    " ![Brightened, Opened then Eroded](005_SecondaryPre-Processing/1103_11_Brighten15_Opened_Eroded_Images.png \"Brightened, Opened then Eroded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset traditional segmentation attempts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "<!-- \n",
    "\n",
    "![alt text](img_path \"mouse hover text\")\n",
    "\n",
    " -->\n",
    "*Default Watershed*:\n",
    "\n",
    " ![Default Watershed](007_Initial_Segmentation/001_Watershed_1_pics.jpg \"Default Watershed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "<!-- \n",
    "\n",
    "![alt text](img_path \"mouse hover text\")\n",
    "\n",
    " -->\n",
    "*Watershed with OpenCV Threshold 17*:\n",
    "\n",
    " ![Watershed with OpenCV Threshold 17](007_Initial_Segmentation/024_WatershedModifiedLast_1_pics.jpg \"Watershed with OpenCV Threshold 17\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "<!-- \n",
    "\n",
    "![alt text](img_path \"mouse hover text\")\n",
    "\n",
    " -->\n",
    "*Canny Edge Detection*:\n",
    "\n",
    " ![Canny Edge Detection](008_Secondary_Segmentation/001_CannyEdgeDetection_50-150_01.jpg \"Canny Edge Detection\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "<!-- \n",
    "\n",
    "![alt text](img_path \"mouse hover text\")\n",
    "\n",
    " -->\n",
    "*Simple Contours*:\n",
    "\n",
    " ![Simple Contours](008_Secondary_Segmentation/002_SimpleContour_01.jpg \"Simple Contours\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "<!-- \n",
    "\n",
    "![alt text](img_path \"mouse hover text\")\n",
    "\n",
    " -->\n",
    "*Complete Contours*:\n",
    "\n",
    " ![Complete Contours](008_Secondary_Segmentation/003_CompleteContour_02.jpg \"Complete Contours\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "<!-- \n",
    "\n",
    "![alt text](img_path \"mouse hover text\")\n",
    "\n",
    " -->\n",
    "*5 Means Clustering*:\n",
    "\n",
    " ![5 Means Clustering](008_Secondary_Segmentation/004_5MeansClustering_02.jpg \"5 Means Clustering\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "<!-- \n",
    "\n",
    "![alt text](img_path \"mouse hover text\")\n",
    "\n",
    " -->\n",
    "*Region Filled*:\n",
    "\n",
    " ![Region Filled](008_Secondary_Segmentation/006_RegionFilled_01.jpg \"Region Filled\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Useful Videos showing Colourmaps and their affect on the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video src=\"003_ColourExploration//BF-C2DL-HSC_01.mp4\" controls  >\n",
       "      Your browser does not support the <code>video</code> element.\n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Video(\"003_ColourExploration//BF-C2DL-HSC_01.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video src=\"003_ColourExploration//DIC-C2DH-HeLa_01.mp4\" controls  >\n",
       "      Your browser does not support the <code>video</code> element.\n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Video(\"003_ColourExploration//DIC-C2DH-HeLa_01.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video src=\"003_ColourExploration//Fluo-C2DL-Huh7_01.mp4\" controls  >\n",
       "      Your browser does not support the <code>video</code> element.\n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Video(\"003_ColourExploration//Fluo-C2DL-Huh7_01.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video src=\"003_ColourExploration//Fluo-C2DL-MSC_01.mp4\" controls  >\n",
       "      Your browser does not support the <code>video</code> element.\n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Video(\"003_ColourExploration//Fluo-C2DL-MSC_01.mp4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Useful Videos showing traditional segmentation techniques alongisde segmentation masks and tracking masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video src=\"009_Segmentation_Videos//BF-C2DL-HSC.mp4\" controls  >\n",
       "      Your browser does not support the <code>video</code> element.\n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Video(\"009_Segmentation_Videos//BF-C2DL-HSC.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video src=\"009_Segmentation_Videos//Fluo-N2DH-GOWT1.mp4\" controls  >\n",
       "      Your browser does not support the <code>video</code> element.\n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Video(\"009_Segmentation_Videos//Fluo-N2DH-GOWT1.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video src=\"009_Segmentation_Videos//PhC-C2DH-U373.mp4\" controls  >\n",
       "      Your browser does not support the <code>video</code> element.\n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "Video(\"009_Segmentation_Videos//PhC-C2DH-U373.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video src=\"009_Segmentation_Videos//PhC-C2DL-PSC.mp4\" controls  >\n",
       "      Your browser does not support the <code>video</code> element.\n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Video(\"009_Segmentation_Videos//PhC-C2DL-PSC.mp4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Data and Their Videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video src=\"010_Training_Data_Videos//GT//BF-C2DL-HSC_02.mp4\" controls  >\n",
       "      Your browser does not support the <code>video</code> element.\n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Video(\"010_Training_Data_Videos//GT//BF-C2DL-HSC_02.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video src=\"010_Training_Data_Videos//GT//Fluo-N2DH-GOWT1_01.mp4\" controls  >\n",
       "      Your browser does not support the <code>video</code> element.\n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Video(\"010_Training_Data_Videos//GT//Fluo-N2DH-GOWT1_01.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video src=\"010_Training_Data_Videos//ST//DIC-C2DH-HeLa_02.mp4\" controls  >\n",
       "      Your browser does not support the <code>video</code> element.\n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "Video(\"010_Training_Data_Videos//ST//DIC-C2DH-HeLa_02.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Video(\"010_Training_Data_Videos//ST//PhC-C2DL-PSC_02.mp4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UNet Implementation and Methodology"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('python_gpu')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b82f63144f2c45b2313238722d81a7c4b83bac7fe75f18d324f42bf6a6cba197"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
