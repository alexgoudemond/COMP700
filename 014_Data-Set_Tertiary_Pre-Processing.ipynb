{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data-Set Tertiary Pre-Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Author: Alexander Goudemond, Student Number: 219030365"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the previous notebooks, the author investigated several processing techniques to try and prepare the data for Training.\n",
    "\n",
    "However, After trying to train a Neural Network, the author has realized the following:\n",
    "\n",
    "- The processed images have a lot of information present in them. This may lead to the network getting confused\n",
    "\n",
    "- The datasets have varying dimensions, and are not always a regular square in shape. The smallest image is (512 x 512) and the largest is (1010 x 1010). This means that if we attempt to resize our images, we lose a lot of information \n",
    "\n",
    "- to avoid pixelation and loss of detail as a result of resizing, we can cut the images into small slices and crop them\n",
    "\n",
    "- If we cut the images into smaller pieces, of some ideal patch size (using Patchify), we can transform a dataset with a small amount of training data (2 images and 2 masks) into a larger collection. However, large collections of data will grow in size as well\n",
    "\n",
    "- The Unet model I have been using comes from Tensorflow, and is pre-trained. Because it is pre-built, the number of available input sizes is fixed. The user can choose between (96, 128, 160, 192, 224) as possible square input sizes\n",
    "\n",
    "- The model's performance has been poor. The author will investigate whether they can produce a more desirable processed image (perhaps one that contains less details in the image) and will then attemp to train on that network, if successful. If the author is unable to do this, they will exhaust training with the Morphological Processed images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, the author is going to do the following:\n",
    "\n",
    "- confirm the unique file dimensions across the datasets\n",
    "\n",
    "- re-examine techniques to try remove unwanted details in the images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import remove, mkdir, walk, getcwd\n",
    "from os.path import exists, join\n",
    "\n",
    "from shutil import move # moves and replaces files\n",
    "\n",
    "import cv2\n",
    "from PIL.Image import fromarray\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checking File Sizes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section of the notebook, we will investigate the size of both the image and the mask from the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['c:\\\\Users\\\\G5\\\\Documents\\\\GitHub\\\\COMP700\\\\..\\\\..\\\\Comp700_DataSets\\\\Extracted\\\\BF-C2DL-HSC\\\\BF-C2DL-HSC\\\\01\\\\t0000.tif', 'c:\\\\Users\\\\G5\\\\Documents\\\\GitHub\\\\COMP700\\\\..\\\\..\\\\Comp700_DataSets\\\\Extracted\\\\BF-C2DL-HSC\\\\BF-C2DL-HSC\\\\01_GT\\\\SEG\\\\man_seg0058.tif', 'c:\\\\Users\\\\G5\\\\Documents\\\\GitHub\\\\COMP700\\\\..\\\\..\\\\Comp700_DataSets\\\\Extracted\\\\BF-C2DL-HSC\\\\BF-C2DL-HSC\\\\01_GT\\\\TRA\\\\man_track0000.tif']\n",
      "Number of images: 96\n"
     ]
    }
   ],
   "source": [
    "desired_directory = \"Comp700_DataSets\"\n",
    "data_sets = getcwd() + \"\\\\..\\\\..\\\\\" + desired_directory\n",
    "\n",
    "sample_image_paths = []\n",
    "\n",
    "for root, dirs, files in walk(data_sets):\n",
    "    if (len(files) != 0):\n",
    "        # only append images\n",
    "        if (\".zip\" not in files[0]):\n",
    "            if (\".txt\" not in files[0]):\n",
    "                sample_image_paths.append( root + \"\\\\\" + files[0] )\n",
    "            else:\n",
    "                sample_image_paths.append( root + \"\\\\\" + files[1] )\n",
    "\n",
    "print(sample_image_paths[0:3])\n",
    "print(\"Number of images:\", len(sample_image_paths))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We know from previous tutorials that the dimensions of the images do not change in the folders, so if we read the dimensions of 1 image, all the other images in that folder will match.\n",
    "\n",
    "We can use this knowledge to generate a dictionary of unique dimensions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractSubstring(path, symbol):\n",
    "    right_most_index = path.rfind(symbol)\n",
    "    return (path[right_most_index + len(symbol) : ])\n",
    "###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BF-C2DL-HSC\\BF-C2DL-HSC\\01\\t0000.tif - (1010,1010,3)\n",
      "BF-C2DL-MuSC\\BF-C2DL-MuSC\\01\\t0000.tif - (1036,1070,3)\n",
      "DIC-C2DH-HeLa\\DIC-C2DH-HeLa\\01\\t000.tif - (512,512,3)\n",
      "Fluo-C2DL-Huh7\\Fluo-C2DL-Huh7\\01\\t000.tif - (1024,1024,3)\n",
      "Fluo-C2DL-MSC\\Fluo-C2DL-MSC\\01\\t000.tif - (832,992,3)\n",
      "Fluo-C2DL-MSC\\Fluo-C2DL-MSC\\02\\t000.tif - (782,1200,3)\n",
      "Fluo-N2DH-SIM+\\Fluo-N2DH-SIM+\\01\\t000.tif - (690,628,3)\n",
      "Fluo-N2DH-SIM+\\Fluo-N2DH-SIM+\\02\\t000.tif - (773,739,3)\n",
      "Fluo-N2DH-SIM+ (1)\\Fluo-N2DH-SIM+ (1)\\01\\t000.tif - (718,660,3)\n",
      "Fluo-N2DH-SIM+ (1)\\Fluo-N2DH-SIM+ (1)\\02\\t000.tif - (790,664,3)\n",
      "Fluo-N2DL-HeLa\\Fluo-N2DL-HeLa\\01\\t000.tif - (700,1100,3)\n",
      "PhC-C2DH-U373\\PhC-C2DH-U373\\01\\t000.tif - (520,696,3)\n",
      "PhC-C2DL-PSC\\PhC-C2DL-PSC\\01\\t000.tif - (576,720,3)\n"
     ]
    }
   ],
   "source": [
    "unique_dimensions = []\n",
    "unique_dimensions_name = []\n",
    "temp = \"\"\n",
    "\n",
    "for image in sample_image_paths:\n",
    "    img = cv2.imread(image)\n",
    "    (x, y, z) = img.shape\n",
    "    temp = \"(\" + str(x) + \",\" + str(y) + \",\" + str(z) + \")\"\n",
    "    \n",
    "    if (temp not in unique_dimensions):\n",
    "        unique_dimensions.append(temp)\n",
    "        unique_dimensions_name.append(extractSubstring(image, \"Extracted\\\\\"))\n",
    "\n",
    "for i in range(len(unique_dimensions)):\n",
    "    print(unique_dimensions_name[i], \"-\", unique_dimensions[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can marry this information with the directories we have as well:"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('python_gpu')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b82f63144f2c45b2313238722d81a7c4b83bac7fe75f18d324f42bf6a6cba197"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
