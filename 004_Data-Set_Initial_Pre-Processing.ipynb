{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data-Set Initial Pre-Processing\n",
    "\n",
    "This notebook focusses on identifying the techniques that may enhance the images in the data-set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49a3d2bf",
   "metadata": {},
   "source": [
    "## Author: Alexander Goudemond, Student Number: 219030365"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import cv2\n",
    "from PIL.Image import fromarray\n",
    "\n",
    "from os import mkdir, getcwd, walk\n",
    "from os.path import join\n",
    "\n",
    "from IPython.display import Video"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary of Previous Work\n",
    "\n",
    "Several valuable pieces of information have emerged as a result of the 2nd (002) and 3rd (003) notebooks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From 002 and 003, we can reflect upon the following:\n",
    "\n",
    "- There are 20 folders, making up the data-sets. Together, these images take up ~7.5 GB (Mostly TIFFs)\n",
    "\n",
    "- There are 10 different kinds of data-set sources, which are listed below:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BF-C2DL-HSC\n",
    "\n",
    "BF-C2DL-MuSC\n",
    "\n",
    "DIC-C2DH-HeLa\n",
    "\n",
    "Fluo-C2DL-Huh7\n",
    "\n",
    "Fluo-C2DL-MSC\n",
    "\n",
    "Fluo-N2DH-GOWT1\n",
    "\n",
    "Fluo-N2DH-SIM+\n",
    "\n",
    "Fluo-N2DL-HeLa\n",
    "\n",
    "PhC-C2DH-U373\n",
    "\n",
    "PhC-C2DL-PSC\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Each of those folders have a training set and a challenge set. The challenge set is denoted by a (1). The main distinction between the folders is that the training sets have manually segmented and manually tracked images for some of the images present. The challenge data-sets ONLY have the images\n",
    "\n",
    "- Windows Photo Viewer and OpenCV are unable to view the features contained in these manually segmented and tracked images. They also cannot show the Simulated Data-Sets (Denoted by a plus symbol above)\n",
    "\n",
    "- Matplotlib.pyplot is able to view all the information in the data-sets, and we can use the built in colourmaps to convert the file into a format that Windows Photo Viewer and OpenCV can then use\n",
    "\n",
    "- Several colourmaps were considered, and cross examined across the 10 data-sets. The 3 recurring colourmaps that may be useful are: 'gray', 'Greys' and 'seismic'. The difference between 'gray' and 'Greys' appears to be the variation of whitelight, as 'Greys' appears whiter\n",
    "\n",
    "- The author generated 4 videos to encapsulate the movement of the cells over time, which includes Colour, Grayscale, Greys and Seismic\n",
    "\n",
    "- In 003, the author stitched a sample of the 4 videos together. 1 example is shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video src=\"ColourExploration\\Fluo-N2DH-SIM+_01.mp4\" controls  >\n",
       "      Your browser does not support the <code>video</code> element.\n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Video(\"ColourExploration\\\\Fluo-N2DH-SIM+_01.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video src=\"ColourExploration\\Fluo-N2DL-HeLa_01.mp4\" controls  >\n",
       "      Your browser does not support the <code>video</code> element.\n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Video(\"ColourExploration\\\\Fluo-N2DL-HeLa_01.mp4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The stitched videos are generated using moviepy, and have 10 frames a second. Thus, some videos stop moving after 5 seconds, whereas other have 10 seconds to display\n",
    "\n",
    "- Fluo-N2DL-HeLa_01.mp4 appears to be white for Colour and Grayscale, but this is probably due to using OpenCV to generate the initial videos. The processing steps of each image will first save the images as 'gray', then be read in via OpenCV\n",
    "\n",
    "The video comparison reveals valuable information:\n",
    "\n",
    "- Colour and Grayscale videos are virtually identical\n",
    "\n",
    "- \"Greys\" brightens the images, which may saturate cells with low intensity values\n",
    "\n",
    "- \"seismic\" creates a kind of heat map, which clearly shows feature movement over time (nucleus, organelles, etc.)\n",
    "\n",
    "- All 4 videos demonstrate a pulsating light effect, which is most noticeable in the 'seismic' data-set. But, all display it upon close inspection\n",
    "\n",
    "- The seismic video is fantastic for identifying cells 'hiding' in the background, with low intensity values\n",
    "\n",
    "All 10 data-sets need to be processed to ensure:\n",
    "\n",
    "- Hidden data is present\n",
    "\n",
    "- Noise is absent\n",
    "\n",
    "- Cell Boundaries are clearly recognized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the synopsis above, we can use this notebook to focus on techniques to process the images!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Images generation\n",
    "\n",
    "Here, we will generate the locations for 10 test images, which will be used to identify valuable processing steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create directory for work we create\n",
    "def tryMakeDirectory(current_directory, destination_directory):\n",
    "    try:\n",
    "        # join comes from os.path\n",
    "        mkdir( join(current_directory, destination_directory) )\n",
    "    except FileExistsError:\n",
    "        print(\"Folder already exists!\")\n",
    "        pass\n",
    "    except:\n",
    "        print(\"Unknown Error Encountered...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory Array\n",
      "['BF-C2DL-HSC', 'BF-C2DL-HSC (1)', 'BF-C2DL-MuSC', 'BF-C2DL-MuSC (1)', 'DIC-C2DH-HeLa', 'DIC-C2DH-HeLa (1)', 'Fluo-C2DL-Huh7', 'Fluo-C2DL-Huh7 (1)', 'Fluo-C2DL-MSC', 'Fluo-C2DL-MSC (1)', 'Fluo-N2DH-GOWT1', 'Fluo-N2DH-GOWT1 (1)', 'Fluo-N2DH-SIM+', 'Fluo-N2DH-SIM+ (1)', 'Fluo-N2DL-HeLa', 'Fluo-N2DL-HeLa (1)', 'PhC-C2DH-U373', 'PhC-C2DH-U373 (1)', 'PhC-C2DL-PSC', 'PhC-C2DL-PSC (1)']\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "We only need to show every _OTHER_ folder, as each data-set has a \n",
    " training and challenge set. So out of 20 files, we need to show 10\n",
    "\n",
    "First things first, let us create an array of the directory locations\n",
    "'''\n",
    "\n",
    "data_sets = \"..\\\\..\\\\Comp700_DataSets\"\n",
    "current_directory = getcwd()\n",
    "\n",
    "path = walk(current_directory + \"\\\\\" + data_sets)\n",
    "\n",
    "directory_array = [] # contains the main folders\n",
    "\n",
    "i = 1\n",
    "for root, dirs, files in path:\n",
    "    if (i == 2):\n",
    "        directory_array = dirs\n",
    "        break\n",
    "    \n",
    "    i += 1\n",
    "\n",
    "print(\"Directory Array\")\n",
    "print(directory_array)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, generate the array of images\n",
    "test_images = []\n",
    "\n",
    "i = -1\n",
    "temp = -1\n",
    "for root, dirs, files in path:\n",
    "    # print(dirs)\n",
    "    for item in files:\n",
    "        # only execute for first picture in directory\n",
    "        if (\"t0000.tif\" == item) or (\"t000.tif\" == item):\n",
    "            i += 1\n",
    "\n",
    "            # skips folder \"02\" in data-sets\n",
    "            if (i % 2 == 1):\n",
    "                break\n",
    "                \n",
    "            # print(i)\n",
    "            temp = i // 2\n",
    "\n",
    "            # skip Challenge data-sets\n",
    "            if (\"(1)\" in directory_array[temp]):\n",
    "                break\n",
    "\n",
    "            location = ( current_directory + \"\\\\\" + data_sets + \"\\\\Extracted\\\\\" + directory_array[temp] + \n",
    "                        \"\\\\\" + directory_array[temp] + \"\\\\01\\\\\" + item)\n",
    "            # print(location)\n",
    "\n",
    "            img = plt.imread(location)\n",
    "\n",
    "            test_images.append(img) # place into array\n",
    "\n",
    "            break\n",
    "\n",
    "        else:\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Label Array\n",
      "['BF-C2DL-HSC', 'BF-C2DL-MuSC', 'DIC-C2DH-HeLa', 'Fluo-C2DL-Huh7', 'Fluo-C2DL-MSC', 'Fluo-N2DH-GOWT1', 'Fluo-N2DH-SIM+', 'Fluo-N2DL-HeLa', 'PhC-C2DH-U373', 'PhC-C2DL-PSC']\n"
     ]
    }
   ],
   "source": [
    "# generate labels for test_images\n",
    "label_array = []\n",
    "\n",
    "for i in range(20):\n",
    "    if (i % 2 == 0):\n",
    "        label_array.append(directory_array[i])\n",
    "\n",
    "print(\"\\nLabel Array\")\n",
    "print(label_array)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, save the images to InitialPreProcessing. Thankfully, Matplotlib.pylot can save them as Tiffs, so our concern in the first notebook is addressed!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the 10 images to our desired folder\n",
    "desired_directory = \"InitialPreProcessing\"\n",
    "\n",
    "i = 0\n",
    "for pic in test_images:\n",
    "    location = current_directory + \"\\\\\" + desired_directory + \"\\\\\" + label_array[i] + \".tiff\"\n",
    "    plt.imsave(location, pic, cmap=\"gray\")\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can read these images in through OpenCV, for our processing needs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenCV - Read in Images\n",
    "\n",
    "Here, we read in the images in our local directory and store them in test_images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us try stitch the 10 images together, to show all 10 videos to the user through OpenCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = walk(desired_directory)\n",
    "\n",
    "test_images = [] # reset variable\n",
    "test_images_names = []\n",
    "\n",
    "for root, dirs, files in path:\n",
    "    for pic_name in files:\n",
    "        if (\".tiff\" in pic_name):\n",
    "            # print(pic_name)\n",
    "            test_images_names.append(pic_name)\n",
    "# print(test_images_names)\n",
    "\n",
    "# read in images in 1 go\n",
    "for i in range(len(test_images_names)):\n",
    "    if (i == 0):\n",
    "        (x, y) = img.shape\n",
    "        \n",
    "    img = cv2.imread(desired_directory + \"\\\\\" + test_images_names[i], cv2.IMREAD_GRAYSCALE)\n",
    "    img_reshaped = cv2.resize(img, (x // 2, y // 2))\n",
    "    test_images.append(img_reshaped)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let us stitch them together!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from PIL.Image import fromarray\n",
    "\n",
    "def stitchTogetherPics(array_of_images):\n",
    "    # top level\n",
    "    myList = (array_of_images[0], array_of_images[1], array_of_images[2], array_of_images[3], array_of_images[4])\n",
    "    numpy_horizontal_top = np.hstack(myList)\n",
    "\n",
    "    # bottom level\n",
    "    myList = (array_of_images[5], array_of_images[6], array_of_images[7], array_of_images[8], array_of_images[9])\n",
    "    numpy_horizontal_bottom = np.hstack(myList)\n",
    "\n",
    "    # stick 2 ontop of one another\n",
    "    myList = (numpy_horizontal_top, numpy_horizontal_bottom)\n",
    "    numpy_final_pic_concat = np.concatenate(myList, axis=0)\n",
    "\n",
    "    return numpy_final_pic_concat\n",
    "\n",
    "def saveAndShow(desired_directory, image_array, picName):\n",
    "    fileName = desired_directory + \"\\\\\" + picName\n",
    "\n",
    "    # Save pic to file, using Pillow!\n",
    "    new_img = fromarray(stitchTogetherPics(image_array))\n",
    "    new_img.save(fileName) # save using Pillow\n",
    "\n",
    "    # show the image to the user\n",
    "    new_img = cv2.imread(fileName, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "    cv2.imshow(picName, new_img)\n",
    "    cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "saveAndShow(desired_directory, test_images, picName=\"01_StitchedImages.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process the images\n",
    "\n",
    "Here, we explore the techniques we can use to process the images. At each junction, JPG versions of the images will be saved to file for reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Useful functions\n",
    "\n",
    "def histEqualization(img):\n",
    "    return cv2.equalizeHist(img)\n",
    "\n",
    "def gaussianSmooth(img, arraySize):\n",
    "    return cv2.GaussianBlur(img, (arraySize,arraySize), 0)\n",
    "\n",
    "def medianSmooth(img, arraySize):\n",
    "    return cv2.medianBlur(img,arraySize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let us loop through and generate an array of histogram corrected images\n",
    "hist_eq_images = []\n",
    "\n",
    "for i in range(len(test_images)):\n",
    "    hist_eq_images.append( histEqualization( test_images[i] ) )\n",
    "\n",
    "picName = \"02_HistogramEqualized.png\"\n",
    "saveAndShow(desired_directory, hist_eq_images, picName)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wow! That is terrible! There is a lot of noise present and a lot of the cell features are lost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Does smoothing improve this?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "gauss_smoothed_hist_eq_images = []\n",
    "\n",
    "for i in range(len(hist_eq_images)):\n",
    "    smoothed_img = gaussianSmooth( hist_eq_images[i], arraySize=3 )\n",
    "    gauss_smoothed_hist_eq_images.append( histEqualization( smoothed_img ) )\n",
    "\n",
    "picName = \"03_GaussianSmoothed_HistogramEqualized.png\"\n",
    "saveAndShow(desired_directory, gauss_smoothed_hist_eq_images, picName)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That didn't seem to help... what about median smoothing?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "median_smoothed_hist_eq_images = []\n",
    "\n",
    "for i in range(len(hist_eq_images)):\n",
    "    smoothed_img = medianSmooth( hist_eq_images[i], arraySize=3 )\n",
    "    median_smoothed_hist_eq_images.append( histEqualization( smoothed_img ) )\n",
    "\n",
    "picName = \"04_MedianSmoothed_HistogramEqualized.png\"\n",
    "saveAndShow(desired_directory, median_smoothed_hist_eq_images, picName)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, the smoothing before histogram equalization is not working... What about just smoothing the images?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "gaussian_smoothed_images = []\n",
    "\n",
    "for i in range(len(test_images)):\n",
    "    smoothed_img = gaussianSmooth( test_images[i], arraySize=3 )\n",
    "    gaussian_smoothed_images.append(smoothed_img)\n",
    "\n",
    "picName = \"05_GaussianSmoothed.png\"\n",
    "saveAndShow(desired_directory, gaussian_smoothed_images, picName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "median_smoothed_images = []\n",
    "\n",
    "for i in range(len(test_images)):\n",
    "    smoothed_img = medianSmooth( test_images[i], arraySize=3 )\n",
    "    median_smoothed_images.append(smoothed_img)\n",
    "\n",
    "picName = \"06_MedianSmoothed.png\"\n",
    "saveAndShow(desired_directory, median_smoothed_images, picName)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above, The standard Smoothing appears to help with some subtle noise, but arraysize can't exceed 3... I should investigate thresholding next"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('tracking_cells')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5172ef57c372de0319e4db714a6087489ed069afeb66a66d936cee1d14e4331d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
