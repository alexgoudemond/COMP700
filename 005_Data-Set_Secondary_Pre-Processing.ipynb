{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data-Set Secondary Pre-Processing\n",
    "\n",
    "This notebook further focusses on processing steps we can use to enhance the images in our data-sets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49a3d2bf",
   "metadata": {},
   "source": [
    "## Author: Alexander Goudemond, Student Number: 219030365"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Previous Results:\n",
    "\n",
    "This section of the notebook summarises the notes from 004"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1105, 1106, 1201 and 1202 are useful to show the user the hidden information in the images. \n",
    "\n",
    "0801 and 0802 are super close at being useful, however, they posses undesirable features\n",
    "\n",
    "0805, 1101 and 1103 may be useful for segmentation\n",
    "\n",
    "It may be worth attempting to try introduce an AND gate between 2 images, in order to extract only the common information. Though this may preserve noise... "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get an idea of what we are hoping to achieve, let us open 2 images from one of our reference materials: Magnussen (PhD Thesis)\n",
    "\n",
    "The images will be available in the COMP700 Proposal, if not provided by the author\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Segmentation Example\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Segmentation Example](Magnusson_Segmentation_Sample.png \"Segmentation Example\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tracking Example Below:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see above, in the segmentation example from Magnussen, (b) is a desirable Processing step before segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At the moment, we have the following desirable affects:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hidden Info present (1105, 1106, 1201, 1202):\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Hidden Info 1](004_InitialPreProcessing\\1105_ErodedNegativeImages.png \"Hidden Info 1\")\n",
    "\n",
    "![Hidden Info 2](004_InitialPreProcessing\\1106_OpenedNegativeImages.png \"Hidden Info 2\")\n",
    "\n",
    "![Hidden Info 3](004_InitialPreProcessing\\1201_HistEq_ErodedAtEnd_BlurAdaptiveThresholdMean.png \"Hidden Info 3\")\n",
    "\n",
    "![Hidden Info 4](004_InitialPreProcessing\\1202_HistE1_OpenedAtStart_BlurAdaptiveThresholdMean.png \"Hidden Info 4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Almost pleasant processed Images (0801, 0802):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Almost Pleasant Processed Images 1](004_InitialPreProcessing\\0801_OtsuThreshold.png \"Almost Pleasant Processed Images 1\")\n",
    "\n",
    "![Almost Pleasant Processed Images 2](004_InitialPreProcessing\\0802_Blur_OtsuThreshold.png \"Almost Pleasant Processed Images 2\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Potential Useful Images (0805, 1101, 1103):\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Potentially Useful Images 1](004_InitialPreProcessing\\0805_BlurAdaptiveThresholdMean.png \"Potentially Useful Images 1\")\n",
    "\n",
    "![Potentially Useful Images 2](004_InitialPreProcessing\\1101_ErodedImages.png \"Potentially Useful Images 2\")\n",
    "\n",
    "![Potentially Useful Images 3](004_InitialPreProcessing\\1103_OpenedImages.png \"Potentially Useful Images 3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see from the 3 pictures above, The processing we are attempting to produce is not of the same quality of Magnussen YET"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the challenges we are facing is to find a processing step that assists all 10 data-sets, because if we only focussed on 1 data-set we would be able to pick a specific processing option... \n",
    "\n",
    "For ease of reference, bottom left of the images above corresponds to Magnussen:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Segmentation Example](Magnusson_Segmentation_Sample.png \"Segmentation Example\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above images, we can visualy see that 1103 is the closest to improving things, but it is rather dark. We need to try use this technique to brighten the overall image, so that we can move forward. The other techniques tried in 004 may be unhelpful as they either help a few data-sets and damage others, or introduce noise...\n",
    "\n",
    "We will carefully explore the combinations here, though"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Infact, upon closer inspection, 1105 and 1106 may be useful after all... Let us carefully compare and contrast 1101, 1103, 1105, 1106"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![1101](004_InitialPreProcessing\\1101_ErodedImages.png \"1101\")\n",
    "\n",
    "![1103](004_InitialPreProcessing\\1103_OpenedImages.png \"1103\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![1105](004_InitialPreProcessing\\1105_ErodedNegativeImages.png \"1105\")\n",
    "\n",
    "![1106](004_InitialPreProcessing\\1106_OpenedNegativeImages.png \"1106\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Between 1101 and 1103, 1103 is better!\n",
    "\n",
    "Between 1105 and 1106, 1106 appears better!\n",
    "\n",
    "Let ys carefully consider 1103 vs 1106"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![1103](004_InitialPreProcessing\\1103_OpenedImages.png \"1103\")\n",
    "\n",
    "![1106](004_InitialPreProcessing\\1106_OpenedNegativeImages.png \"1106\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both 1103 and 1106 contain useful information! We should create videos from them, to cover whether the results are universally good. We are also interested in whether these formatting tools assist with the test cases\n",
    "\n",
    "Of course they are both good! One is an opened image, the other is the negative of it!\n",
    "\n",
    "So instead, let us create a video using the technique from 1106 as well as a video from 0805 to see if our results are helpful"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  1106 and 0805 Videos\n",
    "\n",
    "This section of the notebook focusses on videos using the techniques present in 0805 and 1106, identified in the notebook 004"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section will closely follow the system developed in 003\n",
    "\n",
    "We need a variable containing the Directory Names\n",
    "\n",
    "We need to generate a collection of locations from each of those Directories, for each data-set\n",
    "\n",
    "We need a variable containing the Image Sizes\n",
    "\n",
    "We need 3 functions: processImage, generateVideo, moveVideo\n",
    "\n",
    "Thereafter, we can create small sample videos and save them here, for ease of reference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Directories:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory Array\n",
      "['BF-C2DL-HSC', 'BF-C2DL-HSC (1)', 'BF-C2DL-MuSC', 'BF-C2DL-MuSC (1)', 'DIC-C2DH-HeLa', 'DIC-C2DH-HeLa (1)', 'Fluo-C2DL-Huh7', 'Fluo-C2DL-Huh7 (1)', 'Fluo-C2DL-MSC', 'Fluo-C2DL-MSC (1)', 'Fluo-N2DH-GOWT1', 'Fluo-N2DH-GOWT1 (1)', 'Fluo-N2DH-SIM+', 'Fluo-N2DH-SIM+ (1)', 'Fluo-N2DL-HeLa', 'Fluo-N2DL-HeLa (1)', 'PhC-C2DH-U373', 'PhC-C2DH-U373 (1)', 'PhC-C2DL-PSC', 'PhC-C2DL-PSC (1)']\n"
     ]
    }
   ],
   "source": [
    "from os import getcwd, walk\n",
    "\n",
    "data_sets = \"..\\\\..\\\\Comp700_DataSets\"\n",
    "current_directory = getcwd()\n",
    "\n",
    "path = walk(current_directory + \"\\\\\" + data_sets)\n",
    "\n",
    "directory_array = [] # contains the main folders\n",
    "\n",
    "i = 1\n",
    "for root, dirs, files in path:\n",
    "    if (i == 2):\n",
    "        directory_array = dirs\n",
    "        break\n",
    "    \n",
    "    i += 1\n",
    "\n",
    "print(\"Directory Array\")\n",
    "print(directory_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Locations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['c:\\\\Users\\\\G5\\\\Documents\\\\GitHub\\\\COMP700\\\\..\\\\..\\\\Comp700_DataSets\\\\Extracted\\\\BF-C2DL-HSC\\\\BF-C2DL-HSC\\\\01\\\\', 'c:\\\\Users\\\\G5\\\\Documents\\\\GitHub\\\\COMP700\\\\..\\\\..\\\\Comp700_DataSets\\\\Extracted\\\\BF-C2DL-HSC\\\\BF-C2DL-HSC\\\\02\\\\', 'c:\\\\Users\\\\G5\\\\Documents\\\\GitHub\\\\COMP700\\\\..\\\\..\\\\Comp700_DataSets\\\\Extracted\\\\BF-C2DL-HSC (1)\\\\BF-C2DL-HSC (1)\\\\01\\\\', 'c:\\\\Users\\\\G5\\\\Documents\\\\GitHub\\\\COMP700\\\\..\\\\..\\\\Comp700_DataSets\\\\Extracted\\\\BF-C2DL-HSC (1)\\\\BF-C2DL-HSC (1)\\\\02\\\\', 'c:\\\\Users\\\\G5\\\\Documents\\\\GitHub\\\\COMP700\\\\..\\\\..\\\\Comp700_DataSets\\\\Extracted\\\\BF-C2DL-MuSC\\\\BF-C2DL-MuSC\\\\01\\\\', 'c:\\\\Users\\\\G5\\\\Documents\\\\GitHub\\\\COMP700\\\\..\\\\..\\\\Comp700_DataSets\\\\Extracted\\\\BF-C2DL-MuSC\\\\BF-C2DL-MuSC\\\\02\\\\', 'c:\\\\Users\\\\G5\\\\Documents\\\\GitHub\\\\COMP700\\\\..\\\\..\\\\Comp700_DataSets\\\\Extracted\\\\BF-C2DL-MuSC (1)\\\\BF-C2DL-MuSC (1)\\\\01\\\\', 'c:\\\\Users\\\\G5\\\\Documents\\\\GitHub\\\\COMP700\\\\..\\\\..\\\\Comp700_DataSets\\\\Extracted\\\\BF-C2DL-MuSC (1)\\\\BF-C2DL-MuSC (1)\\\\02\\\\', 'c:\\\\Users\\\\G5\\\\Documents\\\\GitHub\\\\COMP700\\\\..\\\\..\\\\Comp700_DataSets\\\\Extracted\\\\DIC-C2DH-HeLa\\\\DIC-C2DH-HeLa\\\\01\\\\', 'c:\\\\Users\\\\G5\\\\Documents\\\\GitHub\\\\COMP700\\\\..\\\\..\\\\Comp700_DataSets\\\\Extracted\\\\DIC-C2DH-HeLa\\\\DIC-C2DH-HeLa\\\\02\\\\', 'c:\\\\Users\\\\G5\\\\Documents\\\\GitHub\\\\COMP700\\\\..\\\\..\\\\Comp700_DataSets\\\\Extracted\\\\DIC-C2DH-HeLa (1)\\\\DIC-C2DH-HeLa (1)\\\\01\\\\', 'c:\\\\Users\\\\G5\\\\Documents\\\\GitHub\\\\COMP700\\\\..\\\\..\\\\Comp700_DataSets\\\\Extracted\\\\DIC-C2DH-HeLa (1)\\\\DIC-C2DH-HeLa (1)\\\\02\\\\', 'c:\\\\Users\\\\G5\\\\Documents\\\\GitHub\\\\COMP700\\\\..\\\\..\\\\Comp700_DataSets\\\\Extracted\\\\Fluo-C2DL-Huh7\\\\Fluo-C2DL-Huh7\\\\01\\\\', 'c:\\\\Users\\\\G5\\\\Documents\\\\GitHub\\\\COMP700\\\\..\\\\..\\\\Comp700_DataSets\\\\Extracted\\\\Fluo-C2DL-Huh7\\\\Fluo-C2DL-Huh7\\\\02\\\\', 'c:\\\\Users\\\\G5\\\\Documents\\\\GitHub\\\\COMP700\\\\..\\\\..\\\\Comp700_DataSets\\\\Extracted\\\\Fluo-C2DL-Huh7 (1)\\\\Fluo-C2DL-Huh7 (1)\\\\01\\\\', 'c:\\\\Users\\\\G5\\\\Documents\\\\GitHub\\\\COMP700\\\\..\\\\..\\\\Comp700_DataSets\\\\Extracted\\\\Fluo-C2DL-Huh7 (1)\\\\Fluo-C2DL-Huh7 (1)\\\\02\\\\', 'c:\\\\Users\\\\G5\\\\Documents\\\\GitHub\\\\COMP700\\\\..\\\\..\\\\Comp700_DataSets\\\\Extracted\\\\Fluo-C2DL-MSC\\\\Fluo-C2DL-MSC\\\\01\\\\', 'c:\\\\Users\\\\G5\\\\Documents\\\\GitHub\\\\COMP700\\\\..\\\\..\\\\Comp700_DataSets\\\\Extracted\\\\Fluo-C2DL-MSC\\\\Fluo-C2DL-MSC\\\\02\\\\', 'c:\\\\Users\\\\G5\\\\Documents\\\\GitHub\\\\COMP700\\\\..\\\\..\\\\Comp700_DataSets\\\\Extracted\\\\Fluo-C2DL-MSC (1)\\\\Fluo-C2DL-MSC (1)\\\\01\\\\', 'c:\\\\Users\\\\G5\\\\Documents\\\\GitHub\\\\COMP700\\\\..\\\\..\\\\Comp700_DataSets\\\\Extracted\\\\Fluo-C2DL-MSC (1)\\\\Fluo-C2DL-MSC (1)\\\\02\\\\', 'c:\\\\Users\\\\G5\\\\Documents\\\\GitHub\\\\COMP700\\\\..\\\\..\\\\Comp700_DataSets\\\\Extracted\\\\Fluo-N2DH-GOWT1\\\\Fluo-N2DH-GOWT1\\\\01\\\\', 'c:\\\\Users\\\\G5\\\\Documents\\\\GitHub\\\\COMP700\\\\..\\\\..\\\\Comp700_DataSets\\\\Extracted\\\\Fluo-N2DH-GOWT1\\\\Fluo-N2DH-GOWT1\\\\02\\\\', 'c:\\\\Users\\\\G5\\\\Documents\\\\GitHub\\\\COMP700\\\\..\\\\..\\\\Comp700_DataSets\\\\Extracted\\\\Fluo-N2DH-GOWT1 (1)\\\\Fluo-N2DH-GOWT1 (1)\\\\01\\\\', 'c:\\\\Users\\\\G5\\\\Documents\\\\GitHub\\\\COMP700\\\\..\\\\..\\\\Comp700_DataSets\\\\Extracted\\\\Fluo-N2DH-GOWT1 (1)\\\\Fluo-N2DH-GOWT1 (1)\\\\02\\\\', 'c:\\\\Users\\\\G5\\\\Documents\\\\GitHub\\\\COMP700\\\\..\\\\..\\\\Comp700_DataSets\\\\Extracted\\\\Fluo-N2DH-SIM+\\\\Fluo-N2DH-SIM+\\\\01\\\\', 'c:\\\\Users\\\\G5\\\\Documents\\\\GitHub\\\\COMP700\\\\..\\\\..\\\\Comp700_DataSets\\\\Extracted\\\\Fluo-N2DH-SIM+\\\\Fluo-N2DH-SIM+\\\\02\\\\', 'c:\\\\Users\\\\G5\\\\Documents\\\\GitHub\\\\COMP700\\\\..\\\\..\\\\Comp700_DataSets\\\\Extracted\\\\Fluo-N2DH-SIM+ (1)\\\\Fluo-N2DH-SIM+ (1)\\\\01\\\\', 'c:\\\\Users\\\\G5\\\\Documents\\\\GitHub\\\\COMP700\\\\..\\\\..\\\\Comp700_DataSets\\\\Extracted\\\\Fluo-N2DH-SIM+ (1)\\\\Fluo-N2DH-SIM+ (1)\\\\02\\\\', 'c:\\\\Users\\\\G5\\\\Documents\\\\GitHub\\\\COMP700\\\\..\\\\..\\\\Comp700_DataSets\\\\Extracted\\\\Fluo-N2DL-HeLa\\\\Fluo-N2DL-HeLa\\\\01\\\\', 'c:\\\\Users\\\\G5\\\\Documents\\\\GitHub\\\\COMP700\\\\..\\\\..\\\\Comp700_DataSets\\\\Extracted\\\\Fluo-N2DL-HeLa\\\\Fluo-N2DL-HeLa\\\\02\\\\', 'c:\\\\Users\\\\G5\\\\Documents\\\\GitHub\\\\COMP700\\\\..\\\\..\\\\Comp700_DataSets\\\\Extracted\\\\Fluo-N2DL-HeLa (1)\\\\Fluo-N2DL-HeLa (1)\\\\01\\\\', 'c:\\\\Users\\\\G5\\\\Documents\\\\GitHub\\\\COMP700\\\\..\\\\..\\\\Comp700_DataSets\\\\Extracted\\\\Fluo-N2DL-HeLa (1)\\\\Fluo-N2DL-HeLa (1)\\\\02\\\\', 'c:\\\\Users\\\\G5\\\\Documents\\\\GitHub\\\\COMP700\\\\..\\\\..\\\\Comp700_DataSets\\\\Extracted\\\\PhC-C2DH-U373\\\\PhC-C2DH-U373\\\\01\\\\', 'c:\\\\Users\\\\G5\\\\Documents\\\\GitHub\\\\COMP700\\\\..\\\\..\\\\Comp700_DataSets\\\\Extracted\\\\PhC-C2DH-U373\\\\PhC-C2DH-U373\\\\02\\\\', 'c:\\\\Users\\\\G5\\\\Documents\\\\GitHub\\\\COMP700\\\\..\\\\..\\\\Comp700_DataSets\\\\Extracted\\\\PhC-C2DH-U373 (1)\\\\PhC-C2DH-U373 (1)\\\\01\\\\', 'c:\\\\Users\\\\G5\\\\Documents\\\\GitHub\\\\COMP700\\\\..\\\\..\\\\Comp700_DataSets\\\\Extracted\\\\PhC-C2DH-U373 (1)\\\\PhC-C2DH-U373 (1)\\\\02\\\\', 'c:\\\\Users\\\\G5\\\\Documents\\\\GitHub\\\\COMP700\\\\..\\\\..\\\\Comp700_DataSets\\\\Extracted\\\\PhC-C2DL-PSC\\\\PhC-C2DL-PSC\\\\01\\\\', 'c:\\\\Users\\\\G5\\\\Documents\\\\GitHub\\\\COMP700\\\\..\\\\..\\\\Comp700_DataSets\\\\Extracted\\\\PhC-C2DL-PSC\\\\PhC-C2DL-PSC\\\\02\\\\', 'c:\\\\Users\\\\G5\\\\Documents\\\\GitHub\\\\COMP700\\\\..\\\\..\\\\Comp700_DataSets\\\\Extracted\\\\PhC-C2DL-PSC (1)\\\\PhC-C2DL-PSC (1)\\\\01\\\\', 'c:\\\\Users\\\\G5\\\\Documents\\\\GitHub\\\\COMP700\\\\..\\\\..\\\\Comp700_DataSets\\\\Extracted\\\\PhC-C2DL-PSC (1)\\\\PhC-C2DL-PSC (1)\\\\02\\\\']\n"
     ]
    }
   ],
   "source": [
    "# First, generate a list of the locations for each folder of Petri Dish images\n",
    "\n",
    "path = walk(current_directory + \"\\\\\" + data_sets) # reset path\n",
    "\n",
    "location_array = []\n",
    "\n",
    "# used to cycle between 2 folders, present in each directory\n",
    "sub_directory_choice = [\"\\\\01\\\\\", \"\\\\02\\\\\"]\n",
    "\n",
    "i = 0 # will grow from 0 to 39\n",
    "index = 0 # we need to lie in [0, 19]\n",
    "for root, dirs, files in path:\n",
    "    # print(dirs)\n",
    "    for item in files:\n",
    "        if (\"t0000.tif\" == item) or (\"t000.tif\" == item):\n",
    "            index = i // 2\n",
    "\n",
    "            location = ( current_directory + \"\\\\\" + data_sets + \"\\\\Extracted\\\\\" + directory_array[index] + \n",
    "                        \"\\\\\" + directory_array[index] + sub_directory_choice[i % 2])\n",
    "            \n",
    "            i += 1\n",
    "            # print(location)\n",
    "            location_array.append(location)\n",
    "\n",
    "print(location_array)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Image Sizes:\n",
    "\n",
    "We only need to scan the dimensions of the first image as all images in a folder contain the same dimensions!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1010, 1010], [1010, 1010], [1010, 1010], [1010, 1010], [1036, 1070], [1036, 1070], [1036, 1070], [1036, 1070], [512, 512], [512, 512], [512, 512], [512, 512], [1024, 1024], [1024, 1024], [1024, 1024], [1024, 1024], [832, 992], [782, 1200], [832, 992], [782, 1200], [1024, 1024], [1024, 1024], [1024, 1024], [1024, 1024], [690, 628], [773, 739], [718, 660], [790, 664], [700, 1100], [700, 1100], [700, 1100], [700, 1100], [520, 696], [520, 696], [520, 696], [520, 696], [576, 720], [576, 720], [576, 720], [576, 720]]\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "image_size_array = []\n",
    "\n",
    "path = walk(current_directory + \"\\\\\" + data_sets) # reset path\n",
    "\n",
    "i = -1 # will grow from 0 to 39\n",
    "for root, dirs, files in path:\n",
    "    for item in files:\n",
    "        if (\"man_\" not in item) and (\".zip\" not in item):\n",
    "            # update on first element only\n",
    "            if (\"t0000.tif\" == item) or (\"t000.tif\" == item):  \n",
    "                i += 1\n",
    "\n",
    "            img = cv2.imread( (location_array[i] + item), cv2.IMREAD_GRAYSCALE)\n",
    "            (x, y) = img.shape\n",
    "\n",
    "            image_size_array.append([x, y])\n",
    "            break\n",
    "            \n",
    "\n",
    "        # skip \"man_\" images\n",
    "        else:\n",
    "            break\n",
    "\n",
    "print(image_size_array)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import remove, mkdir\n",
    "from os.path import exists, join\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "kernel = np.ones((3,3), np.uint8)\n",
    "\n",
    "# create directory for work we create\n",
    "def tryMakeDirectory(current_directory, destination_directory):\n",
    "    try:\n",
    "        # join comes from os.path\n",
    "        mkdir( join(current_directory, destination_directory) )\n",
    "    except FileExistsError:\n",
    "        print(\"Folder already exists!\")\n",
    "        pass\n",
    "    except:\n",
    "        print(\"Unknown Error Encountered...\")\n",
    "###\n",
    "\n",
    "def openImage(image):\n",
    "    img_erode = cv2.erode(image, kernel, iterations=1)\n",
    "    img_opened = cv2.dilate(img_erode, kernel, iterations=1)\n",
    "\n",
    "    max_val = np.amax(img_opened)\n",
    "    neg_img = max_val - img_opened\n",
    "\n",
    "    return neg_img\n",
    "###\n",
    "\n",
    "def blurredAdaptiveThreshold(image):\n",
    "    max_value = np.amax(image)\n",
    "\n",
    "    blur = cv2.GaussianBlur(image, (5, 5), 0)\n",
    "    thresh_img = cv2.adaptiveThreshold(blur, max_value, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, blockSize=11, C=2)\n",
    "\n",
    "    return thresh_img\n",
    "###\n",
    "\n",
    "# processingChoice == 1 or 2\n",
    "def generateVideos(current_directory, desired_folder, processingChoice):\n",
    "    # only progress if files don't exist\n",
    "    makeVideos = False\n",
    "\n",
    "    if (exists(current_directory + \"\\\\\" + desired_folder)):\n",
    "        # Now, go to directory and verify all is there\n",
    "        path = walk(current_directory + \"\\\\\" + desired_folder)\n",
    "\n",
    "        count = 0\n",
    "        for root, dirs, files in path:\n",
    "            for item in files:\n",
    "                count += 1\n",
    "\n",
    "        if (count == 40):\n",
    "            print(\"All Videos exist already!\")\n",
    "        else:\n",
    "            print(\"Not all Videos exist\")\n",
    "            makeVideos = True\n",
    "    else:\n",
    "        makeVideos = True\n",
    "        \n",
    "    if (makeVideos):\n",
    "        path = walk(current_directory + \"\\\\\" + data_sets) # reset path\n",
    "\n",
    "        sub_directory_choice = [\"01\", \"02\"]\n",
    "\n",
    "        i = -1\n",
    "        output_video = cv2.VideoWriter()\n",
    "        frames_per_second = 10\n",
    "        petri_dish_images = False\n",
    "\n",
    "        # Generates Colour Videos\n",
    "        for root, dirs, files in path:\n",
    "            for item in files:\n",
    "                if (\"man_\" not in item) and (\".zip\" not in item):\n",
    "                    # update on first element only\n",
    "                    if (\"t0000.tif\" == item) or (\"t000.tif\" == item):  \n",
    "\n",
    "                        if (processingChoice == 1):\n",
    "                            fileName = \"blurredAdaptiveThreshold\"\n",
    "                        else:\n",
    "                            fileName = \"Opened\"\n",
    "\n",
    "                        petri_dish_images = True\n",
    "                        i += 1\n",
    "                        index = i // 2 # used for output video as 2 copies for each directory\n",
    "\n",
    "                        size = (image_size_array[i][1], image_size_array[i][0] ) # notice order\n",
    "                        fileName += \"_\" + directory_array[index] + \"_\" + sub_directory_choice[i % 2] + \".mp4\"\n",
    "                        \n",
    "                        output_video = cv2.VideoWriter(\n",
    "                            fileName, \n",
    "                            cv2.VideoWriter_fourcc(*'DIVX'), \n",
    "                            frames_per_second, \n",
    "                            size,\n",
    "                            isColor=False # either True or False\n",
    "                        )\n",
    "\n",
    "                    img = plt.imread( location_array[i] + item) \n",
    "                    plt.imsave(\"temp.jpg\", img, cmap=\"gray\") # desired colourmap for us\n",
    "                    img = cv2.imread( \"temp.jpg\", cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "                    if (processingChoice == 1):\n",
    "                        new_img = blurredAdaptiveThreshold(img)\n",
    "                    else:\n",
    "                        new_img = openImage(img)\n",
    "                        \n",
    "                    output_video.write(new_img)\n",
    "\n",
    "                else:\n",
    "                    petri_dish_images = False\n",
    "                    break\n",
    "                    \n",
    "\n",
    "            if (petri_dish_images):     \n",
    "                cv2.destroyAllWindows()\n",
    "                output_video.release()\n",
    "                print(\"Video finished for \", fileName, sep=\"\")\n",
    "                petri_dish_images = False # update incase next iteration containes empty array\n",
    "    \n",
    "    # remove at end\n",
    "    if (exists(\"temp.jpg\")):\n",
    "        remove(\"temp.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shutil import move # moves and replaces files\n",
    "\n",
    "def moveBulkVideos(current_directory, desired_folder):\n",
    "    # only progress if files don't exist\n",
    "    if (exists(current_directory + \"\\\\\" + desired_folder)):\n",
    "        print(\"Videos already exist!\")\n",
    "    else:\n",
    "        # local function\n",
    "        tryMakeDirectory(current_directory, desired_folder)\n",
    "\n",
    "        path = walk(current_directory)\n",
    "\n",
    "        for root, dirs, files in path:\n",
    "            for item in files:\n",
    "                if (\".mp4\" in item):\n",
    "                    new_destination = current_directory + \"\\\\\" + desired_folder\n",
    "                    move(join(current_directory, item), join(new_destination, item)) # should overwrite existing data\n",
    "\n",
    "        # Now, go to directory and verify all is there\n",
    "        path = walk(current_directory + \"\\\\\" + desired_folder)\n",
    "\n",
    "        count = 0\n",
    "        for root, dirs, files in path:\n",
    "            for item in files:\n",
    "                count += 1\n",
    "\n",
    "        if (count == 40):\n",
    "            print(\"All Videos Moved Successfully!\")\n",
    "        else:\n",
    "            print(\"Not all Videos Moves Successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video finished for blurredAdaptiveThreshold_BF-C2DL-HSC_01.mp4\n",
      "Video finished for blurredAdaptiveThreshold_BF-C2DL-HSC_02.mp4\n",
      "Video finished for blurredAdaptiveThreshold_BF-C2DL-HSC (1)_01.mp4\n",
      "Video finished for blurredAdaptiveThreshold_BF-C2DL-HSC (1)_02.mp4\n",
      "Video finished for blurredAdaptiveThreshold_BF-C2DL-MuSC_01.mp4\n",
      "Video finished for blurredAdaptiveThreshold_BF-C2DL-MuSC_02.mp4\n",
      "Video finished for blurredAdaptiveThreshold_BF-C2DL-MuSC (1)_01.mp4\n",
      "Video finished for blurredAdaptiveThreshold_BF-C2DL-MuSC (1)_02.mp4\n",
      "Video finished for blurredAdaptiveThreshold_DIC-C2DH-HeLa_01.mp4\n",
      "Video finished for blurredAdaptiveThreshold_DIC-C2DH-HeLa_02.mp4\n",
      "Video finished for blurredAdaptiveThreshold_DIC-C2DH-HeLa (1)_01.mp4\n",
      "Video finished for blurredAdaptiveThreshold_DIC-C2DH-HeLa (1)_02.mp4\n",
      "Video finished for blurredAdaptiveThreshold_Fluo-C2DL-Huh7_01.mp4\n",
      "Video finished for blurredAdaptiveThreshold_Fluo-C2DL-Huh7_02.mp4\n",
      "Video finished for blurredAdaptiveThreshold_Fluo-C2DL-Huh7 (1)_01.mp4\n",
      "Video finished for blurredAdaptiveThreshold_Fluo-C2DL-Huh7 (1)_02.mp4\n",
      "Video finished for blurredAdaptiveThreshold_Fluo-C2DL-MSC_01.mp4\n",
      "Video finished for blurredAdaptiveThreshold_Fluo-C2DL-MSC_02.mp4\n",
      "Video finished for blurredAdaptiveThreshold_Fluo-C2DL-MSC (1)_01.mp4\n",
      "Video finished for blurredAdaptiveThreshold_Fluo-C2DL-MSC (1)_02.mp4\n",
      "Video finished for blurredAdaptiveThreshold_Fluo-N2DH-GOWT1_01.mp4\n",
      "Video finished for blurredAdaptiveThreshold_Fluo-N2DH-GOWT1_02.mp4\n",
      "Video finished for blurredAdaptiveThreshold_Fluo-N2DH-GOWT1 (1)_01.mp4\n",
      "Video finished for blurredAdaptiveThreshold_Fluo-N2DH-GOWT1 (1)_02.mp4\n",
      "Video finished for blurredAdaptiveThreshold_Fluo-N2DH-SIM+_01.mp4\n",
      "Video finished for blurredAdaptiveThreshold_Fluo-N2DH-SIM+_02.mp4\n",
      "Video finished for blurredAdaptiveThreshold_Fluo-N2DH-SIM+ (1)_01.mp4\n",
      "Video finished for blurredAdaptiveThreshold_Fluo-N2DH-SIM+ (1)_02.mp4\n",
      "Video finished for blurredAdaptiveThreshold_Fluo-N2DL-HeLa_01.mp4\n",
      "Video finished for blurredAdaptiveThreshold_Fluo-N2DL-HeLa_02.mp4\n",
      "Video finished for blurredAdaptiveThreshold_Fluo-N2DL-HeLa (1)_01.mp4\n",
      "Video finished for blurredAdaptiveThreshold_Fluo-N2DL-HeLa (1)_02.mp4\n",
      "Video finished for blurredAdaptiveThreshold_PhC-C2DH-U373_01.mp4\n",
      "Video finished for blurredAdaptiveThreshold_PhC-C2DH-U373_02.mp4\n",
      "Video finished for blurredAdaptiveThreshold_PhC-C2DH-U373 (1)_01.mp4\n",
      "Video finished for blurredAdaptiveThreshold_PhC-C2DH-U373 (1)_02.mp4\n",
      "Video finished for blurredAdaptiveThreshold_PhC-C2DL-PSC_01.mp4\n",
      "Video finished for blurredAdaptiveThreshold_PhC-C2DL-PSC_02.mp4\n",
      "Video finished for blurredAdaptiveThreshold_PhC-C2DL-PSC (1)_01.mp4\n",
      "Video finished for blurredAdaptiveThreshold_PhC-C2DL-PSC (1)_02.mp4\n"
     ]
    }
   ],
   "source": [
    "generateVideos(current_directory, \"..\\\\..\\\\COMP700_VideosOfDataSets_BlurAdaptiveThreshold\", 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Videos already exist!\n"
     ]
    }
   ],
   "source": [
    "moveBulkVideos(current_directory, \"..\\\\..\\\\COMP700_VideosOfDataSets_BlurAdaptiveThreshold\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Those videos were generated successfully, however they have an incredible amount of noise and further processing may disrupt the cell borders. Let us next focus on generating the Opened Videos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video finished for Opened_BF-C2DL-HSC_01.mp4\n",
      "Video finished for Opened_BF-C2DL-HSC_02.mp4\n",
      "Video finished for Opened_BF-C2DL-HSC (1)_01.mp4\n",
      "Video finished for Opened_BF-C2DL-HSC (1)_02.mp4\n",
      "Video finished for Opened_BF-C2DL-MuSC_01.mp4\n",
      "Video finished for Opened_BF-C2DL-MuSC_02.mp4\n",
      "Video finished for Opened_BF-C2DL-MuSC (1)_01.mp4\n",
      "Video finished for Opened_BF-C2DL-MuSC (1)_02.mp4\n",
      "Video finished for Opened_DIC-C2DH-HeLa_01.mp4\n",
      "Video finished for Opened_DIC-C2DH-HeLa_02.mp4\n",
      "Video finished for Opened_DIC-C2DH-HeLa (1)_01.mp4\n",
      "Video finished for Opened_DIC-C2DH-HeLa (1)_02.mp4\n",
      "Video finished for Opened_Fluo-C2DL-Huh7_01.mp4\n",
      "Video finished for Opened_Fluo-C2DL-Huh7_02.mp4\n",
      "Video finished for Opened_Fluo-C2DL-Huh7 (1)_01.mp4\n",
      "Video finished for Opened_Fluo-C2DL-Huh7 (1)_02.mp4\n",
      "Video finished for Opened_Fluo-C2DL-MSC_01.mp4\n",
      "Video finished for Opened_Fluo-C2DL-MSC_02.mp4\n",
      "Video finished for Opened_Fluo-C2DL-MSC (1)_01.mp4\n",
      "Video finished for Opened_Fluo-C2DL-MSC (1)_02.mp4\n",
      "Video finished for Opened_Fluo-N2DH-GOWT1_01.mp4\n",
      "Video finished for Opened_Fluo-N2DH-GOWT1_02.mp4\n",
      "Video finished for Opened_Fluo-N2DH-GOWT1 (1)_01.mp4\n",
      "Video finished for Opened_Fluo-N2DH-GOWT1 (1)_02.mp4\n",
      "Video finished for Opened_Fluo-N2DH-SIM+_01.mp4\n",
      "Video finished for Opened_Fluo-N2DH-SIM+_02.mp4\n",
      "Video finished for Opened_Fluo-N2DH-SIM+ (1)_01.mp4\n",
      "Video finished for Opened_Fluo-N2DH-SIM+ (1)_02.mp4\n",
      "Video finished for Opened_Fluo-N2DL-HeLa_01.mp4\n",
      "Video finished for Opened_Fluo-N2DL-HeLa_02.mp4\n",
      "Video finished for Opened_Fluo-N2DL-HeLa (1)_01.mp4\n",
      "Video finished for Opened_Fluo-N2DL-HeLa (1)_02.mp4\n",
      "Video finished for Opened_PhC-C2DH-U373_01.mp4\n",
      "Video finished for Opened_PhC-C2DH-U373_02.mp4\n",
      "Video finished for Opened_PhC-C2DH-U373 (1)_01.mp4\n",
      "Video finished for Opened_PhC-C2DH-U373 (1)_02.mp4\n",
      "Video finished for Opened_PhC-C2DL-PSC_01.mp4\n",
      "Video finished for Opened_PhC-C2DL-PSC_02.mp4\n",
      "Video finished for Opened_PhC-C2DL-PSC (1)_01.mp4\n",
      "Video finished for Opened_PhC-C2DL-PSC (1)_02.mp4\n"
     ]
    }
   ],
   "source": [
    "generateVideos(current_directory, \"..\\\\..\\\\COMP700_VideosOfDataSets_Opened\", 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'c:\\\\Users\\\\G5\\\\Documents\\\\GitHub\\\\COMP700\\\\BF-C2DL-HSC_01.mp4'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\G5\\anaconda3\\envs\\tracking_cells\\lib\\shutil.py:813\u001b[0m, in \u001b[0;36mmove\u001b[1;34m(src, dst, copy_function)\u001b[0m\n\u001b[0;32m    812\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 813\u001b[0m     os\u001b[39m.\u001b[39;49mrename(src, real_dst)\n\u001b[0;32m    814\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mOSError\u001b[39;00m:\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 2] The system cannot find the file specified: 'c:\\\\Users\\\\G5\\\\Documents\\\\GitHub\\\\COMP700\\\\BF-C2DL-HSC_01.mp4' -> 'c:\\\\Users\\\\G5\\\\Documents\\\\GitHub\\\\COMP700\\\\..\\\\..\\\\COMP700_VideosOfDataSets_Opened\\\\BF-C2DL-HSC_01.mp4'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\G5\\Documents\\GitHub\\COMP700\\005_Data-Set_Secondary_Pre-Processing.ipynb Cell 43\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/G5/Documents/GitHub/COMP700/005_Data-Set_Secondary_Pre-Processing.ipynb#ch0000043?line=0'>1</a>\u001b[0m moveBulkVideos(current_directory, \u001b[39m\"\u001b[39;49m\u001b[39m..\u001b[39;49m\u001b[39m\\\\\u001b[39;49;00m\u001b[39m..\u001b[39;49m\u001b[39m\\\\\u001b[39;49;00m\u001b[39mCOMP700_VideosOfDataSets_Opened\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "\u001b[1;32mc:\\Users\\G5\\Documents\\GitHub\\COMP700\\005_Data-Set_Secondary_Pre-Processing.ipynb Cell 43\u001b[0m in \u001b[0;36mmoveBulkVideos\u001b[1;34m(current_directory, desired_folder)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/G5/Documents/GitHub/COMP700/005_Data-Set_Secondary_Pre-Processing.ipynb#ch0000043?line=14'>15</a>\u001b[0m         \u001b[39mif\u001b[39;00m (\u001b[39m\"\u001b[39m\u001b[39m.mp4\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m item):\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/G5/Documents/GitHub/COMP700/005_Data-Set_Secondary_Pre-Processing.ipynb#ch0000043?line=15'>16</a>\u001b[0m             new_destination \u001b[39m=\u001b[39m current_directory \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m\\\\\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m desired_folder\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/G5/Documents/GitHub/COMP700/005_Data-Set_Secondary_Pre-Processing.ipynb#ch0000043?line=16'>17</a>\u001b[0m             move(join(current_directory, item), join(new_destination, item)) \u001b[39m# should overwrite existing data\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/G5/Documents/GitHub/COMP700/005_Data-Set_Secondary_Pre-Processing.ipynb#ch0000043?line=18'>19</a>\u001b[0m \u001b[39m# Now, go to directory and verify all is there\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/G5/Documents/GitHub/COMP700/005_Data-Set_Secondary_Pre-Processing.ipynb#ch0000043?line=19'>20</a>\u001b[0m path \u001b[39m=\u001b[39m walk(current_directory \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m\\\\\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m desired_folder)\n",
      "File \u001b[1;32mc:\\Users\\G5\\anaconda3\\envs\\tracking_cells\\lib\\shutil.py:833\u001b[0m, in \u001b[0;36mmove\u001b[1;34m(src, dst, copy_function)\u001b[0m\n\u001b[0;32m    831\u001b[0m         rmtree(src)\n\u001b[0;32m    832\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 833\u001b[0m         copy_function(src, real_dst)\n\u001b[0;32m    834\u001b[0m         os\u001b[39m.\u001b[39munlink(src)\n\u001b[0;32m    835\u001b[0m \u001b[39mreturn\u001b[39;00m real_dst\n",
      "File \u001b[1;32mc:\\Users\\G5\\anaconda3\\envs\\tracking_cells\\lib\\shutil.py:434\u001b[0m, in \u001b[0;36mcopy2\u001b[1;34m(src, dst, follow_symlinks)\u001b[0m\n\u001b[0;32m    432\u001b[0m \u001b[39mif\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39misdir(dst):\n\u001b[0;32m    433\u001b[0m     dst \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(dst, os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mbasename(src))\n\u001b[1;32m--> 434\u001b[0m copyfile(src, dst, follow_symlinks\u001b[39m=\u001b[39;49mfollow_symlinks)\n\u001b[0;32m    435\u001b[0m copystat(src, dst, follow_symlinks\u001b[39m=\u001b[39mfollow_symlinks)\n\u001b[0;32m    436\u001b[0m \u001b[39mreturn\u001b[39;00m dst\n",
      "File \u001b[1;32mc:\\Users\\G5\\anaconda3\\envs\\tracking_cells\\lib\\shutil.py:254\u001b[0m, in \u001b[0;36mcopyfile\u001b[1;34m(src, dst, follow_symlinks)\u001b[0m\n\u001b[0;32m    252\u001b[0m     os\u001b[39m.\u001b[39msymlink(os\u001b[39m.\u001b[39mreadlink(src), dst)\n\u001b[0;32m    253\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 254\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39;49m(src, \u001b[39m'\u001b[39;49m\u001b[39mrb\u001b[39;49m\u001b[39m'\u001b[39;49m) \u001b[39mas\u001b[39;00m fsrc:\n\u001b[0;32m    255\u001b[0m         \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    256\u001b[0m             \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(dst, \u001b[39m'\u001b[39m\u001b[39mwb\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mas\u001b[39;00m fdst:\n\u001b[0;32m    257\u001b[0m                 \u001b[39m# macOS\u001b[39;00m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'c:\\\\Users\\\\G5\\\\Documents\\\\GitHub\\\\COMP700\\\\BF-C2DL-HSC_01.mp4'"
     ]
    }
   ],
   "source": [
    "moveBulkVideos(current_directory, \"..\\\\..\\\\COMP700_VideosOfDataSets_Opened\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('tracking_cells')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5172ef57c372de0319e4db714a6087489ed069afeb66a66d936cee1d14e4331d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
