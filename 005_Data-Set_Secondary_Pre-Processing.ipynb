{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data-Set Secondary Pre-Processing\n",
    "\n",
    "This notebook further focusses on processing steps we can use to enhance the images in our data-sets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49a3d2bf",
   "metadata": {},
   "source": [
    "## Author: Alexander Goudemond, Student Number: 219030365"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import remove, mkdir\n",
    "from os.path import exists, join\n",
    "\n",
    "from shutil import move # moves and replaces files\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Previous Results:\n",
    "\n",
    "This section of the notebook summarises the notes from 004"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1105, 1106, 1201 and 1202 are useful to show the user the hidden information in the images. \n",
    "\n",
    "0801 and 0802 are super close at being useful, however, they posses undesirable features\n",
    "\n",
    "0805, 1101 and 1103 may be useful for segmentation\n",
    "\n",
    "It may be worth attempting to try introduce an AND gate between 2 images, in order to extract only the common information. Though this may preserve noise... "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get an idea of what we are hoping to achieve, let us open 2 images from one of our reference materials: Magnussen (PhD Thesis)\n",
    "\n",
    "The images will be available in the COMP700 Proposal, if not provided by the author\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Segmentation Example\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Segmentation Example](Magnusson_Segmentation_Sample.png \"Segmentation Example\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tracking Example Below:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see above, in the segmentation example from Magnussen, (b) is a desirable Processing step before segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At the moment, we have the following desirable affects:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hidden Info present (1105, 1106, 1201, 1202):\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Hidden Info 1](004_InitialPreProcessing\\1105_ErodedNegativeImages.png \"Hidden Info 1\")\n",
    "\n",
    "![Hidden Info 2](004_InitialPreProcessing\\1106_OpenedNegativeImages.png \"Hidden Info 2\")\n",
    "\n",
    "![Hidden Info 3](004_InitialPreProcessing\\1201_HistEq_ErodedAtEnd_BlurAdaptiveThresholdMean.png \"Hidden Info 3\")\n",
    "\n",
    "![Hidden Info 4](004_InitialPreProcessing\\1202_HistE1_OpenedAtStart_BlurAdaptiveThresholdMean.png \"Hidden Info 4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Almost pleasant processed Images (0801, 0802):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Almost Pleasant Processed Images 1](004_InitialPreProcessing\\0801_OtsuThreshold.png \"Almost Pleasant Processed Images 1\")\n",
    "\n",
    "![Almost Pleasant Processed Images 2](004_InitialPreProcessing\\0802_Blur_OtsuThreshold.png \"Almost Pleasant Processed Images 2\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Potential Useful Images (0805, 1101, 1103):\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Potentially Useful Images 1](004_InitialPreProcessing\\0805_BlurAdaptiveThresholdMean.png \"Potentially Useful Images 1\")\n",
    "\n",
    "![Potentially Useful Images 2](004_InitialPreProcessing\\1101_ErodedImages.png \"Potentially Useful Images 2\")\n",
    "\n",
    "![Potentially Useful Images 3](004_InitialPreProcessing\\1103_OpenedImages.png \"Potentially Useful Images 3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see from the 3 pictures above, The processing we are attempting to produce is not of the same quality of Magnussen YET"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the challenges we are facing is to find a processing step that assists all 10 data-sets, because if we only focussed on 1 data-set we would be able to pick a specific processing option... \n",
    "\n",
    "For ease of reference, bottom left of the images above corresponds to Magnussen:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Segmentation Example](Magnusson_Segmentation_Sample.png \"Segmentation Example\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above images, we can visualy see that 1103 is the closest to improving things, but it is rather dark. We need to try use this technique to brighten the overall image, so that we can move forward. The other techniques tried in 004 may be unhelpful as they either help a few data-sets and damage others, or introduce noise...\n",
    "\n",
    "We will carefully explore the combinations here, though"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Infact, upon closer inspection, 1105 and 1106 may be useful after all... Let us carefully compare and contrast 1101, 1103, 1105, 1106"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![1101](004_InitialPreProcessing\\1101_ErodedImages.png \"1101\")\n",
    "\n",
    "![1103](004_InitialPreProcessing\\1103_OpenedImages.png \"1103\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![1105](004_InitialPreProcessing\\1105_ErodedNegativeImages.png \"1105\")\n",
    "\n",
    "![1106](004_InitialPreProcessing\\1106_OpenedNegativeImages.png \"1106\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Between 1101 and 1103, 1103 is better!\n",
    "\n",
    "Between 1105 and 1106, 1106 appears better!\n",
    "\n",
    "Let us carefully consider 1103 vs 1106"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![1103](004_InitialPreProcessing\\1103_OpenedImages.png \"1103\")\n",
    "\n",
    "![1106](004_InitialPreProcessing\\1106_OpenedNegativeImages.png \"1106\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both 1103 and 1106 contain useful information! We should create videos from them, to cover whether the results are universally good. We are also interested in whether these formatting tools assist with the test cases\n",
    "\n",
    "Of course they are both good! One is an opened image, the other is the negative of it!\n",
    "\n",
    "So instead, let us create a video using the technique from 1106 as well as a video from 0805 to see if our results are helpful"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  1106 and 0805 Videos\n",
    "\n",
    "This section of the notebook focusses on videos using the techniques present in 0805 and 1106, identified in the notebook 004"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section will closely follow the system developed in 003:\n",
    "\n",
    "- We need a variable containing the Directory Names\n",
    "\n",
    "- We need to generate a collection of locations from each of those Directories, for each data-set\n",
    "\n",
    "- We need a variable containing the Image Sizes\n",
    "\n",
    "- We need 4 functions: processImage x 2, generateVideo, moveVideo\n",
    "\n",
    "- Thereafter, we can create small sample videos and save them here, for ease of reference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Directories:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory Array\n",
      "['BF-C2DL-HSC', 'BF-C2DL-HSC (1)', 'BF-C2DL-MuSC', 'BF-C2DL-MuSC (1)', 'DIC-C2DH-HeLa', 'DIC-C2DH-HeLa (1)', 'Fluo-C2DL-Huh7', 'Fluo-C2DL-Huh7 (1)', 'Fluo-C2DL-MSC', 'Fluo-C2DL-MSC (1)', 'Fluo-N2DH-GOWT1', 'Fluo-N2DH-GOWT1 (1)', 'Fluo-N2DH-SIM+', 'Fluo-N2DH-SIM+ (1)', 'Fluo-N2DL-HeLa', 'Fluo-N2DL-HeLa (1)', 'PhC-C2DH-U373', 'PhC-C2DH-U373 (1)', 'PhC-C2DL-PSC', 'PhC-C2DL-PSC (1)']\n"
     ]
    }
   ],
   "source": [
    "from os import getcwd, walk\n",
    "\n",
    "data_sets = \"..\\\\..\\\\Comp700_DataSets\"\n",
    "current_directory = getcwd()\n",
    "\n",
    "path = walk(current_directory + \"\\\\\" + data_sets)\n",
    "\n",
    "directory_array = [] # contains the main folders\n",
    "\n",
    "i = 1\n",
    "for root, dirs, files in path:\n",
    "    if (i == 2):\n",
    "        directory_array = dirs\n",
    "        break\n",
    "    \n",
    "    i += 1\n",
    "\n",
    "print(\"Directory Array\")\n",
    "print(directory_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Locations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['c:\\\\Users\\\\G5\\\\Documents\\\\GitHub\\\\COMP700\\\\..\\\\..\\\\Comp700_DataSets\\\\Extracted\\\\BF-C2DL-HSC\\\\BF-C2DL-HSC\\\\01\\\\', 'c:\\\\Users\\\\G5\\\\Documents\\\\GitHub\\\\COMP700\\\\..\\\\..\\\\Comp700_DataSets\\\\Extracted\\\\BF-C2DL-HSC\\\\BF-C2DL-HSC\\\\02\\\\', 'c:\\\\Users\\\\G5\\\\Documents\\\\GitHub\\\\COMP700\\\\..\\\\..\\\\Comp700_DataSets\\\\Extracted\\\\BF-C2DL-HSC (1)\\\\BF-C2DL-HSC (1)\\\\01\\\\', 'c:\\\\Users\\\\G5\\\\Documents\\\\GitHub\\\\COMP700\\\\..\\\\..\\\\Comp700_DataSets\\\\Extracted\\\\BF-C2DL-HSC (1)\\\\BF-C2DL-HSC (1)\\\\02\\\\', 'c:\\\\Users\\\\G5\\\\Documents\\\\GitHub\\\\COMP700\\\\..\\\\..\\\\Comp700_DataSets\\\\Extracted\\\\BF-C2DL-MuSC\\\\BF-C2DL-MuSC\\\\01\\\\', 'c:\\\\Users\\\\G5\\\\Documents\\\\GitHub\\\\COMP700\\\\..\\\\..\\\\Comp700_DataSets\\\\Extracted\\\\BF-C2DL-MuSC\\\\BF-C2DL-MuSC\\\\02\\\\', 'c:\\\\Users\\\\G5\\\\Documents\\\\GitHub\\\\COMP700\\\\..\\\\..\\\\Comp700_DataSets\\\\Extracted\\\\BF-C2DL-MuSC (1)\\\\BF-C2DL-MuSC (1)\\\\01\\\\', 'c:\\\\Users\\\\G5\\\\Documents\\\\GitHub\\\\COMP700\\\\..\\\\..\\\\Comp700_DataSets\\\\Extracted\\\\BF-C2DL-MuSC (1)\\\\BF-C2DL-MuSC (1)\\\\02\\\\', 'c:\\\\Users\\\\G5\\\\Documents\\\\GitHub\\\\COMP700\\\\..\\\\..\\\\Comp700_DataSets\\\\Extracted\\\\DIC-C2DH-HeLa\\\\DIC-C2DH-HeLa\\\\01\\\\', 'c:\\\\Users\\\\G5\\\\Documents\\\\GitHub\\\\COMP700\\\\..\\\\..\\\\Comp700_DataSets\\\\Extracted\\\\DIC-C2DH-HeLa\\\\DIC-C2DH-HeLa\\\\02\\\\', 'c:\\\\Users\\\\G5\\\\Documents\\\\GitHub\\\\COMP700\\\\..\\\\..\\\\Comp700_DataSets\\\\Extracted\\\\DIC-C2DH-HeLa (1)\\\\DIC-C2DH-HeLa (1)\\\\01\\\\', 'c:\\\\Users\\\\G5\\\\Documents\\\\GitHub\\\\COMP700\\\\..\\\\..\\\\Comp700_DataSets\\\\Extracted\\\\DIC-C2DH-HeLa (1)\\\\DIC-C2DH-HeLa (1)\\\\02\\\\', 'c:\\\\Users\\\\G5\\\\Documents\\\\GitHub\\\\COMP700\\\\..\\\\..\\\\Comp700_DataSets\\\\Extracted\\\\Fluo-C2DL-Huh7\\\\Fluo-C2DL-Huh7\\\\01\\\\', 'c:\\\\Users\\\\G5\\\\Documents\\\\GitHub\\\\COMP700\\\\..\\\\..\\\\Comp700_DataSets\\\\Extracted\\\\Fluo-C2DL-Huh7\\\\Fluo-C2DL-Huh7\\\\02\\\\', 'c:\\\\Users\\\\G5\\\\Documents\\\\GitHub\\\\COMP700\\\\..\\\\..\\\\Comp700_DataSets\\\\Extracted\\\\Fluo-C2DL-Huh7 (1)\\\\Fluo-C2DL-Huh7 (1)\\\\01\\\\', 'c:\\\\Users\\\\G5\\\\Documents\\\\GitHub\\\\COMP700\\\\..\\\\..\\\\Comp700_DataSets\\\\Extracted\\\\Fluo-C2DL-Huh7 (1)\\\\Fluo-C2DL-Huh7 (1)\\\\02\\\\', 'c:\\\\Users\\\\G5\\\\Documents\\\\GitHub\\\\COMP700\\\\..\\\\..\\\\Comp700_DataSets\\\\Extracted\\\\Fluo-C2DL-MSC\\\\Fluo-C2DL-MSC\\\\01\\\\', 'c:\\\\Users\\\\G5\\\\Documents\\\\GitHub\\\\COMP700\\\\..\\\\..\\\\Comp700_DataSets\\\\Extracted\\\\Fluo-C2DL-MSC\\\\Fluo-C2DL-MSC\\\\02\\\\', 'c:\\\\Users\\\\G5\\\\Documents\\\\GitHub\\\\COMP700\\\\..\\\\..\\\\Comp700_DataSets\\\\Extracted\\\\Fluo-C2DL-MSC (1)\\\\Fluo-C2DL-MSC (1)\\\\01\\\\', 'c:\\\\Users\\\\G5\\\\Documents\\\\GitHub\\\\COMP700\\\\..\\\\..\\\\Comp700_DataSets\\\\Extracted\\\\Fluo-C2DL-MSC (1)\\\\Fluo-C2DL-MSC (1)\\\\02\\\\', 'c:\\\\Users\\\\G5\\\\Documents\\\\GitHub\\\\COMP700\\\\..\\\\..\\\\Comp700_DataSets\\\\Extracted\\\\Fluo-N2DH-GOWT1\\\\Fluo-N2DH-GOWT1\\\\01\\\\', 'c:\\\\Users\\\\G5\\\\Documents\\\\GitHub\\\\COMP700\\\\..\\\\..\\\\Comp700_DataSets\\\\Extracted\\\\Fluo-N2DH-GOWT1\\\\Fluo-N2DH-GOWT1\\\\02\\\\', 'c:\\\\Users\\\\G5\\\\Documents\\\\GitHub\\\\COMP700\\\\..\\\\..\\\\Comp700_DataSets\\\\Extracted\\\\Fluo-N2DH-GOWT1 (1)\\\\Fluo-N2DH-GOWT1 (1)\\\\01\\\\', 'c:\\\\Users\\\\G5\\\\Documents\\\\GitHub\\\\COMP700\\\\..\\\\..\\\\Comp700_DataSets\\\\Extracted\\\\Fluo-N2DH-GOWT1 (1)\\\\Fluo-N2DH-GOWT1 (1)\\\\02\\\\', 'c:\\\\Users\\\\G5\\\\Documents\\\\GitHub\\\\COMP700\\\\..\\\\..\\\\Comp700_DataSets\\\\Extracted\\\\Fluo-N2DH-SIM+\\\\Fluo-N2DH-SIM+\\\\01\\\\', 'c:\\\\Users\\\\G5\\\\Documents\\\\GitHub\\\\COMP700\\\\..\\\\..\\\\Comp700_DataSets\\\\Extracted\\\\Fluo-N2DH-SIM+\\\\Fluo-N2DH-SIM+\\\\02\\\\', 'c:\\\\Users\\\\G5\\\\Documents\\\\GitHub\\\\COMP700\\\\..\\\\..\\\\Comp700_DataSets\\\\Extracted\\\\Fluo-N2DH-SIM+ (1)\\\\Fluo-N2DH-SIM+ (1)\\\\01\\\\', 'c:\\\\Users\\\\G5\\\\Documents\\\\GitHub\\\\COMP700\\\\..\\\\..\\\\Comp700_DataSets\\\\Extracted\\\\Fluo-N2DH-SIM+ (1)\\\\Fluo-N2DH-SIM+ (1)\\\\02\\\\', 'c:\\\\Users\\\\G5\\\\Documents\\\\GitHub\\\\COMP700\\\\..\\\\..\\\\Comp700_DataSets\\\\Extracted\\\\Fluo-N2DL-HeLa\\\\Fluo-N2DL-HeLa\\\\01\\\\', 'c:\\\\Users\\\\G5\\\\Documents\\\\GitHub\\\\COMP700\\\\..\\\\..\\\\Comp700_DataSets\\\\Extracted\\\\Fluo-N2DL-HeLa\\\\Fluo-N2DL-HeLa\\\\02\\\\', 'c:\\\\Users\\\\G5\\\\Documents\\\\GitHub\\\\COMP700\\\\..\\\\..\\\\Comp700_DataSets\\\\Extracted\\\\Fluo-N2DL-HeLa (1)\\\\Fluo-N2DL-HeLa (1)\\\\01\\\\', 'c:\\\\Users\\\\G5\\\\Documents\\\\GitHub\\\\COMP700\\\\..\\\\..\\\\Comp700_DataSets\\\\Extracted\\\\Fluo-N2DL-HeLa (1)\\\\Fluo-N2DL-HeLa (1)\\\\02\\\\', 'c:\\\\Users\\\\G5\\\\Documents\\\\GitHub\\\\COMP700\\\\..\\\\..\\\\Comp700_DataSets\\\\Extracted\\\\PhC-C2DH-U373\\\\PhC-C2DH-U373\\\\01\\\\', 'c:\\\\Users\\\\G5\\\\Documents\\\\GitHub\\\\COMP700\\\\..\\\\..\\\\Comp700_DataSets\\\\Extracted\\\\PhC-C2DH-U373\\\\PhC-C2DH-U373\\\\02\\\\', 'c:\\\\Users\\\\G5\\\\Documents\\\\GitHub\\\\COMP700\\\\..\\\\..\\\\Comp700_DataSets\\\\Extracted\\\\PhC-C2DH-U373 (1)\\\\PhC-C2DH-U373 (1)\\\\01\\\\', 'c:\\\\Users\\\\G5\\\\Documents\\\\GitHub\\\\COMP700\\\\..\\\\..\\\\Comp700_DataSets\\\\Extracted\\\\PhC-C2DH-U373 (1)\\\\PhC-C2DH-U373 (1)\\\\02\\\\', 'c:\\\\Users\\\\G5\\\\Documents\\\\GitHub\\\\COMP700\\\\..\\\\..\\\\Comp700_DataSets\\\\Extracted\\\\PhC-C2DL-PSC\\\\PhC-C2DL-PSC\\\\01\\\\', 'c:\\\\Users\\\\G5\\\\Documents\\\\GitHub\\\\COMP700\\\\..\\\\..\\\\Comp700_DataSets\\\\Extracted\\\\PhC-C2DL-PSC\\\\PhC-C2DL-PSC\\\\02\\\\', 'c:\\\\Users\\\\G5\\\\Documents\\\\GitHub\\\\COMP700\\\\..\\\\..\\\\Comp700_DataSets\\\\Extracted\\\\PhC-C2DL-PSC (1)\\\\PhC-C2DL-PSC (1)\\\\01\\\\', 'c:\\\\Users\\\\G5\\\\Documents\\\\GitHub\\\\COMP700\\\\..\\\\..\\\\Comp700_DataSets\\\\Extracted\\\\PhC-C2DL-PSC (1)\\\\PhC-C2DL-PSC (1)\\\\02\\\\']\n"
     ]
    }
   ],
   "source": [
    "# First, generate a list of the locations for each folder of Petri Dish images\n",
    "\n",
    "path = walk(current_directory + \"\\\\\" + data_sets) # reset path\n",
    "\n",
    "location_array = []\n",
    "\n",
    "# used to cycle between 2 folders, present in each directory\n",
    "sub_directory_choice = [\"\\\\01\\\\\", \"\\\\02\\\\\"]\n",
    "\n",
    "i = 0 # will grow from 0 to 39\n",
    "index = 0 # we need to lie in [0, 19]\n",
    "for root, dirs, files in path:\n",
    "    # print(dirs)\n",
    "    for item in files:\n",
    "        if (\"t0000.tif\" == item) or (\"t000.tif\" == item):\n",
    "            index = i // 2\n",
    "\n",
    "            location = ( current_directory + \"\\\\\" + data_sets + \"\\\\Extracted\\\\\" + directory_array[index] + \n",
    "                        \"\\\\\" + directory_array[index] + sub_directory_choice[i % 2])\n",
    "            \n",
    "            i += 1\n",
    "            # print(location)\n",
    "            location_array.append(location)\n",
    "\n",
    "print(location_array)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Image Sizes:\n",
    "\n",
    "We only need to scan the dimensions of the first image as all images in a folder contain the same dimensions!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1010, 1010], [1010, 1010], [1010, 1010], [1010, 1010], [1036, 1070], [1036, 1070], [1036, 1070], [1036, 1070], [512, 512], [512, 512], [512, 512], [512, 512], [1024, 1024], [1024, 1024], [1024, 1024], [1024, 1024], [832, 992], [782, 1200], [832, 992], [782, 1200], [1024, 1024], [1024, 1024], [1024, 1024], [1024, 1024], [690, 628], [773, 739], [718, 660], [790, 664], [700, 1100], [700, 1100], [700, 1100], [700, 1100], [520, 696], [520, 696], [520, 696], [520, 696], [576, 720], [576, 720], [576, 720], [576, 720]]\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "image_size_array = []\n",
    "\n",
    "path = walk(current_directory + \"\\\\\" + data_sets) # reset path\n",
    "\n",
    "i = -1 # will grow from 0 to 39\n",
    "for root, dirs, files in path:\n",
    "    for item in files:\n",
    "        if (\"man_\" not in item) and (\".zip\" not in item):\n",
    "            # update on first element only\n",
    "            if (\"t0000.tif\" == item) or (\"t000.tif\" == item):  \n",
    "                i += 1\n",
    "\n",
    "            img = cv2.imread( (location_array[i] + item), cv2.IMREAD_GRAYSCALE)\n",
    "            (x, y) = img.shape\n",
    "\n",
    "            image_size_array.append([x, y])\n",
    "            break\n",
    "            \n",
    "\n",
    "        # skip \"man_\" images\n",
    "        else:\n",
    "            break\n",
    "\n",
    "print(image_size_array)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kernel for Morphological Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = np.ones((3,3), np.uint8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Useful Functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create directory for work we create\n",
    "def tryMakeDirectory(current_directory, destination_directory):\n",
    "    try:\n",
    "        # join comes from os.path\n",
    "        mkdir( join(current_directory, destination_directory) )\n",
    "    except FileExistsError:\n",
    "        print(\"Folder already exists!\")\n",
    "        pass\n",
    "    except:\n",
    "        print(\"Unknown Error Encountered...\")\n",
    "###\n",
    "\n",
    "def openImage(image):\n",
    "    img_erode = cv2.erode(image, kernel, iterations=1)\n",
    "    img_opened = cv2.dilate(img_erode, kernel, iterations=1)\n",
    "\n",
    "    max_val = np.amax(img_opened)\n",
    "    neg_img = max_val - img_opened\n",
    "\n",
    "    return neg_img\n",
    "###\n",
    "\n",
    "def blurredAdaptiveThreshold(image):\n",
    "    max_value = np.amax(image)\n",
    "\n",
    "    blur = cv2.GaussianBlur(image, (5, 5), 0)\n",
    "    thresh_img = cv2.adaptiveThreshold(blur, max_value, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, blockSize=11, C=2)\n",
    "\n",
    "    return thresh_img\n",
    "###\n",
    "\n",
    "# processingChoice == 1 or 2\n",
    "def generateVideos(current_directory, desired_folder, processingChoice):\n",
    "    # only progress if files don't exist\n",
    "    makeVideos = False\n",
    "\n",
    "    if (exists(current_directory + \"\\\\\" + desired_folder)):\n",
    "        # Now, go to directory and verify all is there\n",
    "        path = walk(current_directory + \"\\\\\" + desired_folder)\n",
    "\n",
    "        count = 0\n",
    "        for root, dirs, files in path:\n",
    "            for item in files:\n",
    "                count += 1\n",
    "\n",
    "        if (count == 40):\n",
    "            print(\"All Videos exist already!\")\n",
    "        else:\n",
    "            print(\"Not all Videos exist\")\n",
    "            makeVideos = True\n",
    "    else:\n",
    "        makeVideos = True\n",
    "        \n",
    "    if (makeVideos):\n",
    "        path = walk(current_directory + \"\\\\\" + data_sets) # reset path\n",
    "\n",
    "        sub_directory_choice = [\"01\", \"02\"]\n",
    "\n",
    "        i = -1\n",
    "        output_video = cv2.VideoWriter()\n",
    "        frames_per_second = 10\n",
    "        petri_dish_images = False\n",
    "\n",
    "        # Generates Colour Videos\n",
    "        for root, dirs, files in path:\n",
    "            for item in files:\n",
    "                if (\"man_\" not in item) and (\".zip\" not in item):\n",
    "                    # update on first element only\n",
    "                    if (\"t0000.tif\" == item) or (\"t000.tif\" == item):  \n",
    "\n",
    "                        if (processingChoice == 1):\n",
    "                            fileName = \"blurredAdaptiveThreshold\"\n",
    "                        else:\n",
    "                            fileName = \"Opened\"\n",
    "\n",
    "                        petri_dish_images = True\n",
    "                        i += 1\n",
    "                        index = i // 2 # used for output video as 2 copies for each directory\n",
    "\n",
    "                        size = (image_size_array[i][1], image_size_array[i][0] ) # notice order\n",
    "                        fileName += \"_\" + directory_array[index] + \"_\" + sub_directory_choice[i % 2] + \".mp4\"\n",
    "                        \n",
    "                        output_video = cv2.VideoWriter(\n",
    "                            fileName, \n",
    "                            cv2.VideoWriter_fourcc(*'DIVX'), \n",
    "                            frames_per_second, \n",
    "                            size,\n",
    "                            isColor=False # either True or False\n",
    "                        )\n",
    "\n",
    "                    img = plt.imread( location_array[i] + item) \n",
    "                    plt.imsave(\"temp.jpg\", img, cmap=\"gray\") # desired colourmap for us\n",
    "                    img = cv2.imread( \"temp.jpg\", cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "                    if (processingChoice == 1):\n",
    "                        new_img = blurredAdaptiveThreshold(img)\n",
    "                    else:\n",
    "                        new_img = openImage(img)\n",
    "                        \n",
    "                    output_video.write(new_img)\n",
    "\n",
    "                else:\n",
    "                    petri_dish_images = False\n",
    "                    break\n",
    "                    \n",
    "\n",
    "            if (petri_dish_images):     \n",
    "                cv2.destroyAllWindows()\n",
    "                output_video.release()\n",
    "                print(\"Video finished for \", fileName, sep=\"\")\n",
    "                petri_dish_images = False # update incase next iteration containes empty array\n",
    "    \n",
    "    # remove at end\n",
    "    if (exists(\"temp.jpg\")):\n",
    "        remove(\"temp.jpg\")\n",
    "###\n",
    "\n",
    "def moveBulkVideos(current_directory, desired_folder):\n",
    "    # only progress if files don't exist\n",
    "    if (exists(current_directory + \"\\\\\" + desired_folder)):\n",
    "        print(\"Videos already exist!\")\n",
    "    else:\n",
    "        # local function\n",
    "        tryMakeDirectory(current_directory, desired_folder)\n",
    "\n",
    "        path = walk(current_directory)\n",
    "\n",
    "        for root, dirs, files in path:\n",
    "            for item in files:\n",
    "                if (\".mp4\" in item):\n",
    "                    new_destination = current_directory + \"\\\\\" + desired_folder\n",
    "                    move(join(current_directory, item), join(new_destination, item)) # should overwrite existing data\n",
    "\n",
    "        # Now, go to directory and verify all is there\n",
    "        path = walk(current_directory + \"\\\\\" + desired_folder)\n",
    "\n",
    "        count = 0\n",
    "        for root, dirs, files in path:\n",
    "            for item in files:\n",
    "                count += 1\n",
    "\n",
    "        if (count == 40):\n",
    "            print(\"All Videos Moved Successfully!\")\n",
    "        else:\n",
    "            print(\"Not all Videos Moves Successfully\")\n",
    "###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All Videos exist already!\n"
     ]
    }
   ],
   "source": [
    "generateVideos(current_directory, \"..\\\\..\\\\Comp700_VideosOfDataSets_BlurAdaptiveThreshold\", 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Videos already exist!\n"
     ]
    }
   ],
   "source": [
    "moveBulkVideos(current_directory, \"..\\\\..\\\\Comp700_VideosOfDataSets_BlurAdaptiveThreshold\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Those videos were generated successfully, however they have an incredible amount of noise and further processing may disrupt the cell borders. We will create small snippets of those videos to show the reader soon\n",
    "\n",
    "\n",
    "Let us next focus on generating the Opened Videos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All Videos exist already!\n"
     ]
    }
   ],
   "source": [
    "generateVideos(current_directory, \"..\\\\..\\\\Comp700_VideosOfDataSets_Opened\", 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Videos already exist!\n"
     ]
    }
   ],
   "source": [
    "moveBulkVideos(current_directory, \"..\\\\..\\\\Comp700_VideosOfDataSets_Opened\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Video Snippets\n",
    "\n",
    "This section of the notebook looks at snippets of 3 videos and placing them together to better understand the change in form"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we seek to do is create snippets of the videos from: Seismic, BlurAdaptiveMean and Opened and compare them for 10 data-sets (Just the 01 folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from moviepy.editor import *\n",
    "from IPython.display import Video"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we need to generate a variable with the locations of each video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Comp700_VideosOfDataSets_BlurAdaptiveThreshold', 'Comp700_VideosOfDataSets_Colour', 'Comp700_VideosOfDataSets_Grayscale', 'Comp700_VideosOfDataSets_Greys', 'Comp700_VideosOfDataSets_Opened', 'Comp700_VideosOfDataSets_Seismic']\n"
     ]
    }
   ],
   "source": [
    "# from os import getcwd, walk\n",
    "\n",
    "desired_directory = getcwd() + \"\\\\..\\\\..\"\n",
    "# print(desired_directory)\n",
    "\n",
    "path = walk(desired_directory)\n",
    "\n",
    "directories = []\n",
    "\n",
    "# extract first directory list\n",
    "for root, dirs, files in path:\n",
    "    directories = dirs\n",
    "    break\n",
    "\n",
    "# print(directories)\n",
    "\n",
    "# Extract 4 folders of videos\n",
    "\n",
    "video_directories = []\n",
    "\n",
    "for item in directories:\n",
    "    if (\"Comp700_Videos\" in item):\n",
    "        video_directories.append(item)\n",
    "\n",
    "print(video_directories)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We seek to stitch Seismic, BlurAdaptiveThreshold and Opened images together"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('tracking_cells')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5172ef57c372de0319e4db714a6087489ed069afeb66a66d936cee1d14e4331d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
